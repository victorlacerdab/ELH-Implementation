{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import owlready2 as owl\n",
    "from owlready2 import *\n",
    "owlready2.reasoning.JAVA_MEMORY = 20000\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_pytorch_dataset import GeometricInterpretation, CanonicalModel, EntityEmbedding, SCALE_FACTOR\n",
    "from create_pytorch_dataset import entity_to_idx_vocab, concept_to_idx_vocab, role_to_idx_vocab, idx_to_entity_vocab, idx_to_concept_vocab, idx_to_role_vocab, idx_finder_dict\n",
    "from create_pytorch_dataset import trainConceptDataset, testConceptDataset, trainRoleDataset, testRoleDataset, train_ConceptDataLoader, test_ConceptDataLoader, train_RoleDataLoader, test_RoleDataLoader, RoleDataLoader, ConceptDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FaithEL_model import FaithEL\n",
    "from utils import save_model, train_model, plot_score_hak, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_loss_role, compute_loss_concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for databatch in RoleDataLoader:\n",
    "    for epoch in range (1, EPOCHS):\n",
    "        samples, labels = databatch\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out1, out2, out3, out4 = model(samples)\n",
    "        loss = compute_loss_role(out1, out2, out3, out4, labels, loss_fn, GAMMA, PHI, neg_sampling=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for databatch in ConceptDataLoader:\n",
    "    for epoch in range (1, EPOCHS):\n",
    "        samples, labels = databatch\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out1, out2, out3, out4 = model(samples)\n",
    "        loss = compute_loss_concept(out1, out2, out3, labels, loss_fn, GAMMA, PHI, neg_sampling=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def take_distance(model, RoleDataLoader):\n",
    "    centroid_role = model.role_embedding_dict.weight[0]\n",
    "    \n",
    "    for batch in RoleDataLoader:\n",
    "        batch = batch[0]\n",
    "        for sample in batch:\n",
    "            print(f'Role assertion in ontology: r({sample[0]+1}.{sample[2]+1})')\n",
    "\n",
    "    print('')\n",
    "    for m, individual1 in enumerate(model.individual_embedding_dict.weight):\n",
    "        for n, individual2 in enumerate(model.individual_embedding_dict.weight):\n",
    "            concat = torch.cat((individual1, individual2), axis=0)\n",
    "            print(f'Distance of concat(Q{m+1}, Q{n+1}) to role centroid: {torch.dist(concat, centroid_role)}')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take_distance(model, RoleDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTROID_SCORE = True # When set to True, model scores assertion w.r.t distance to the centroid and to the moving parameter for concepts/roles\n",
    "LR = 0.001\n",
    "PHI = 1 # Weighs the loss obtained by computing the distance between the role/concept params to the centroid\n",
    "GAMMA = 1 # Weighs the loss obtained by computing the distance between the role/concept param to the individual/ind_concat parameters\n",
    "RADIUS = SCALE_FACTOR/2 + 0.1\n",
    "EMB_DIM = 459\n",
    "\n",
    "LOG_EPOCH = 10000\n",
    "EVAL_TRAIN = True\n",
    "EPOCHS = 250\n",
    "EVAL_FREQ = 5\n",
    "\n",
    "NEG_SAMPLING = True\n",
    "PLOT_LOSS = True\n",
    "\n",
    "DIM1 = 0\n",
    "DIM2 = 1\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(269)\n",
    "\n",
    "model = FaithEL(EMB_DIM, PHI, RADIUS, GAMMA,\n",
    "                entity_to_idx_vocab, concept_to_idx_vocab, role_to_idx_vocab,\n",
    "                )\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, GeometricInterpretation, idx_to_entity_vocab, idx_to_concept_vocab, idx_to_role_vocab, SCALE_FACTOR, DIM1, DIM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, test_loss_list, train_hits_at_k_concept, test_hits_at_k_concept, train_hits_at_k_role, test_hits_at_k_role, = train_model(model, GeometricInterpretation,\n",
    "                                                                                                                                           train_ConceptDataLoader, train_RoleDataLoader, test_ConceptDataLoader, test_RoleDataLoader,\n",
    "                                                                                                                                           trainConceptDataset, testConceptDataset, trainRoleDataset, testRoleDataset,\n",
    "                                                                                                                                           EPOCHS, LOG_EPOCH, EVAL_FREQ, EVAL_TRAIN, loss_fn, optimizer,\n",
    "                                                                                                                                           idx_to_entity_vocab, entity_to_idx_vocab,\n",
    "                                                                                                                                           idx_to_concept_vocab, concept_to_idx_vocab,\n",
    "                                                                                                                                           idx_to_role_vocab, role_to_idx_vocab,\n",
    "                                                                                                                                           CENTROID_SCORE, NEG_SAMPLING, PLOT_LOSS\n",
    "                                                                                                                                           )\n",
    "\n",
    "model_list.append(save_model(CENTROID_SCORE, LR, PHI, GAMMA, EMB_DIM, EPOCHS, LOG_EPOCH, EVAL_FREQ, EVAL_TRAIN,\n",
    "                             loss_fn, model, optimizer, train_loss_list, test_loss_list, train_hits_at_k_concept, test_hits_at_k_concept, train_hits_at_k_role, test_hits_at_k_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, GeometricInterpretation, idx_to_entity_vocab, idx_to_concept_vocab, idx_to_role_vocab, SCALE_FACTOR, DIM1, DIM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = -1\n",
    "TOPK = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_hak(model_list[pos_list]['test_hits_at_k_concept'], model_list[pos_list]['test_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])\n",
    "plot_score_hak(model_list[pos_list]['train_hits_at_k_concept'], model_list[pos_list]['train_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
