{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def negative_sampler_concept(self, data):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Review this code\n",
    "            \n",
    "            # Sort the real batch by concept number and individual number\n",
    "            print(f'data: {data}')\n",
    "            print(f'data shape {data.shape}')\n",
    "\n",
    "            sorted_concepts_idcs = torch.argsort(data[:,0])\n",
    "            sorted_concepts_data = data[sorted_concepts_idcs]\n",
    "            sorted_individual_idcs = torch.argsort(sorted_concepts_data[:,1] +\n",
    "                                                   sorted_concepts_data[:,0] *\n",
    "                                                   sorted_concepts_data.size(0))\n",
    "            sorted_data_final = sorted_concepts_data[sorted_individual_idcs]\n",
    "\n",
    "            print(f'sorted real batch conflict samples{sorted_data_final}')\n",
    "            \n",
    "            # Generate negative candidates and sort the corrupted batch\n",
    "\n",
    "            neg_sampled_candidates = torch.randint(0, self.individual_embedding_dict.weight.shape[0], (data.shape[0],))\n",
    "            corrupted_batch = torch.cat((data[:,0].unsqueeze(1), neg_sampled_candidates.unsqueeze(1)), dim=1)\n",
    "            sorted_neg_concepts_idcs = sorted_concepts_idcs # Reutilize the previous sorting operation\n",
    "            sorted_neg_concepts_batch = corrupted_batch[sorted_neg_concepts_idcs]\n",
    "            sorted_corrupted_individual_idcs = torch.argsort(sorted_neg_concepts_batch[:,1] +\n",
    "                                                             sorted_neg_concepts_batch[:,0] *\n",
    "                                                             sorted_neg_concepts_batch.size(0))\n",
    "            sorted_corrupted_batch_final = sorted_neg_concepts_batch[sorted_corrupted_individual_idcs]\n",
    "\n",
    "            print(f'sorted corrupted conflict samples{sorted_corrupted_batch_final}')\n",
    "\n",
    "            # While there are identical samples in both real and corrupted batches, generate more corrupted individuals\n",
    "\n",
    "            # We check whether any assertion in our negatively sampled individuals is in the batch\n",
    "            \n",
    "            counter = 0\n",
    "            MAX_ITER = 50000\n",
    "\n",
    "            negsamp_checker = sorted_data_final[:,1] == sorted_corrupted_batch_final[:,1]\n",
    "\n",
    "            while torch.any(negsamp_checker) and counter != MAX_ITER:\n",
    "        \n",
    "                conflict_idcs = torch.where(negsamp_checker == True)[0]\n",
    "                for idx in conflict_idcs:\n",
    "                    sorted_corrupted_batch_final[idx][1] = torch.randint(0, self.individual_embedding_dict.weight.shape[0], (1,)).item()\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            if counter == MAX_ITER:\n",
    "                print('loop limit reached')\n",
    "                #print(f'neg_sampchecker TRUE: {negsamp_checker}')\n",
    "                where_conflict = torch.where(negsamp_checker)[0]\n",
    "\n",
    "            # Return only the individuals, discarding concepts\n",
    "            return sorted_corrupted_batch_final[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
