{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import owlready2 as owl\n",
    "from owlready2 import *\n",
    "import types\n",
    "owlready2.reasoning.JAVA_MEMORY = 6000\n",
    "\n",
    "import scipy\n",
    "#from scipy.spatial import ConvexHull\n",
    "#import cdd\n",
    "#from cdd import RepType, Matrix, Polyhedron\n",
    "#from fractions import Fraction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/goslimyeast.xml.owl'\n",
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/galennorm.xml.owl'\n",
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/gonorm.xml.owl'\n",
    "dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/family_ontology.owl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onto = get_ontology(dir)\n",
    "onto = onto.load()\n",
    "\n",
    "individuals = list(onto.individuals())\n",
    "roles = list(onto.properties())\n",
    "classes = list(onto.classes())\n",
    "gcas = list(onto.general_class_axioms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes = list(onto.classes())\n",
    "\n",
    "for cls in classes:\n",
    "    print(f'{cls} Ancestors: {cls.ancestors(include_self = True, include_constructs = True)}')\n",
    "    #print(f'{cls} Constructs: {list(cls.constructs())}')\n",
    "    #print(f'{cls} Properties: {list(cls.get_class_properties())}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with onto:\n",
    "    sync_reasoner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes = list(onto.classes())\n",
    "\n",
    "for cls in classes:\n",
    "    print(f'{cls} Ancestors: {cls.ancestors(include_self = True, include_constructs = True)}')\n",
    "    print(f'{cls} Constructs: {list(cls.constructs())}')\n",
    "    print(f'{cls} Properties: {list(cls.get_class_properties())}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class for creating entities to\n",
    "populate the creation of the\n",
    "canonical models.\n",
    "\n",
    "The .name attribute is used to\n",
    "create a single representation\n",
    "for concepts like A and B / \n",
    "B and A, as they are the same.\n",
    "'''\n",
    "\n",
    "class CanonicalModelElements:\n",
    "\n",
    "    concept_names = {}\n",
    "    concept_intersections = {}\n",
    "    concept_restrictions = {}\n",
    "    all_concepts = {}\n",
    "\n",
    "    def __init__(self, concept):\n",
    "        self.concept = concept\n",
    "        self.name = self.get_name()\n",
    "        self.get_element_dict()\n",
    "\n",
    "    def get_name(self):\n",
    "\n",
    "        # add \\Top\n",
    "        \n",
    "        if type(self.concept) == ThingClass:\n",
    "            return self.concept.name\n",
    "\n",
    "        elif type(self.concept) == Restriction:\n",
    "            return 'exists_' + self.concept.property.name + '.' + self.concept.value.name\n",
    "        \n",
    "        else:\n",
    "            return 'And_' + ''.join(sorted(self.concept.Classes[0].name + self.concept.Classes[1].name)) # The name is sorted to avoid that (e.g) (A \\and B) and (B \\and A) are treated as different concepts\n",
    "        \n",
    "    def get_element_dict(self):\n",
    "\n",
    "        if type(self.concept) == ThingClass:\n",
    "            CanonicalModelElements.concept_names[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self\n",
    "\n",
    "        elif type(self.concept) == Restriction:\n",
    "            CanonicalModelElements.concept_restrictions[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self\n",
    "\n",
    "        elif type(self.concept) == And:\n",
    "            CanonicalModelElements.concept_intersections[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canonical_model_elements(concept_names_iter, role_names_iter, ontology):\n",
    "    \n",
    "    onto = ontology\n",
    "    top = owl.Thing\n",
    "    bottom = owl.Nothing\n",
    "\n",
    "    CanonicalModelElements(top)\n",
    "    CanonicalModelElements(bottom)\n",
    "\n",
    "    for concept_name in concept_names_iter:\n",
    "        \n",
    "        CanonicalModelElements(concept_name)\n",
    "        for concept_name2 in concept_names_iter:\n",
    "        \n",
    "            with onto:\n",
    "                gca = GeneralClassAxiom(concept_name & concept_name2)\n",
    "                gca.is_a.append(concept_name & concept_name2)\n",
    "            \n",
    "            CanonicalModelElements(gca.left_side)\n",
    "\n",
    "    print('')\n",
    "    print('===========================================================================================================')\n",
    "    print('All Concept Names and Concept Intersections have been preprocessed for the creation of the canonical model.')\n",
    "    print('===========================================================================================================')\n",
    "\n",
    "    concept_names_iter.append(top)\n",
    "    # concept_names_iter.append(bottom)\n",
    "\n",
    "    for role_name in role_names_iter:\n",
    "        for concept_name in concept_names_iter:\n",
    "            with onto:\n",
    "                gca = GeneralClassAxiom(role_name.some(concept_name))\n",
    "                gca.is_a.append(role_name.some(concept_name))\n",
    "\n",
    "            CanonicalModelElements(gca.left_side)\n",
    "\n",
    "    print('')\n",
    "    print('')\n",
    "    print('All restrictions have been preprocessed for the creation of the canonical model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The main class for creating the canonical model for the ontology.\n",
    "\n",
    "The canonical model is stored in dictionaries available as class variables 'concept_canonical_interpretation'\n",
    "and 'role_canonical_interpretation'. \n",
    "\n",
    "Args:\n",
    "    concept_names_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    concept_intersection_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    concept_restrictions_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    all_concepts_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    role_names_iter (list): a list containing all role names in the loaded ontology.\n",
    "'''\n",
    "\n",
    "class CanonicalModel:\n",
    "\n",
    "    concept_canonical_interpretation = {}\n",
    "    role_canonical_interpretation = {}\n",
    "\n",
    "    def __init__(self, concept_names_dict, concept_intersections_dict, concept_restrictions_dict, all_concepts_dict, role_names_iter):\n",
    "        \n",
    "        self.domain = all_concepts_dict\n",
    "        self.concept_names_dict = concept_names_dict\n",
    "        self.concept_restrictions_dict = concept_restrictions_dict\n",
    "        self.concept_intersections_dict = concept_intersections_dict\n",
    "\n",
    "        self.role_names_iter = role_names_iter\n",
    "\n",
    "        self.concept_canonical_interp = self.get_concept_name_caninterp() # These are only used to build the concept_canonical_interpretation and role_canonical_interpretation class attributes\n",
    "        self.role_canonical_interp = self.get_role_name_caninterp()       # The functions do not return anything, they just update their corresponding class variables \n",
    "\n",
    "    def get_concept_name_caninterp(self):\n",
    "\n",
    "        # The variable concept is a string containing the name of an element of the domain of the canonical model\n",
    "        # The key to the concept_names_dict variable corresponds to concept.name\n",
    "        # This name can be used to access the concept in owlready2's format\n",
    "\n",
    "        for concept in self.concept_names_dict.keys():\n",
    "\n",
    "            CanonicalModel.concept_canonical_interpretation[concept] = []\n",
    "            superclasses = self.domain[concept].concept.ancestors(include_self=True, include_constructs=True) # The self.domain[concept] is used to access the CanonicalModelElements type of object,\n",
    "                                                                                                               # and the attribute .concept is used to access the concept in owlready2 format\n",
    "                                                                                                              \n",
    "            for superclass in superclasses:\n",
    "\n",
    "                if type(superclass) == ThingClass:\n",
    "                    CanonicalModel.concept_canonical_interpretation[concept].append(superclass.name)\n",
    "\n",
    "                elif type(superclass) == Restriction:\n",
    "                    CanonicalModel.concept_canonical_interpretation[concept].append('exists_' + superclass.property.name + '.' + superclass.value.name)\n",
    "\n",
    "                elif type(superclass) == And:\n",
    "                    if 'And_' + ''.join(sorted(superclass.Classes[0].name + superclass.Classes[1].name)) in CanonicalModel.concept_canonical_interpretation[concept]:\n",
    "                        pass\n",
    "                    else:\n",
    "                        CanonicalModel.concept_canonical_interpretation[concept].append('And_' + ''.join(sorted(superclass.Classes[0].name + superclass.Classes[1].name)))\n",
    "\n",
    "    def get_role_name_caninterp(self):\n",
    "\n",
    "        # First case from Definition 10\n",
    "\n",
    "        for role_name in self.role_names_iter:\n",
    "\n",
    "            role_name_str = role_name.name # Accesses the property type object's name as a string\n",
    "            CanonicalModel.role_canonical_interpretation[role_name_str] = []\n",
    "\n",
    "            for restriction_name in self.concept_restrictions_dict.keys(): # Where restriction_name denotes a \\exists r.B type of concept 'exists_' + self.concept.property.name + '.' + self.concept.value.name\n",
    "                c_B = self.concept_restrictions_dict[restriction_name].concept.value.name\n",
    "\n",
    "                if role_name_str in restriction_name:\n",
    "                    superclasses = self.domain[restriction_name].concept.ancestors(include_self=True, include_constructs=False)\n",
    "\n",
    "                    for superclass in superclasses:\n",
    "                        super_superclasses = superclass.ancestors(include_self=True, include_constructs=True)\n",
    "\n",
    "                        for super_superclass in super_superclasses:\n",
    "\n",
    "                            if type(super_superclass) == ThingClass:\n",
    "                                c_D = super_superclass.name\n",
    "                                CanonicalModel.role_canonical_interpretation[role_name_str].append(tuple(c_D, c_B))\n",
    "\n",
    "                            elif type(super_superclass) == Restriction:\n",
    "                                c_D = 'exists_' + super_superclass.property.name + '.' + super_superclass.value.name\n",
    "                                CanonicalModel.role_canonical_interpretation[role_name_str].append(tuple(c_D, c_B))\n",
    "\n",
    "                            elif type(super_superclass) == And:\n",
    "                                c_D = 'And_' + ''.join(sorted(super_superclass.Classes[0].name + super_superclass.Classes[1].name))\n",
    "                                CanonicalModel.role_canonical_interpretation[role_name_str].append(tuple(c_D, c_B))\n",
    "\n",
    "        # Second case from Definition 10: r \\sqsubset s \n",
    "            \n",
    "        for role_name in self.role_names_iter:\n",
    "\n",
    "            superroles = role_name.ancestors(include_self=True)\n",
    "            role_name_str = role_name.name\n",
    "            \n",
    "            for superrole in superroles:\n",
    "                for restriction_name in self.concept_restrictions_dict.keys():\n",
    "                    if superrole.name in restriction_name:\n",
    "                        pair = tuple((restriction_name, self.domain[restriction_name].concept.value.name))\n",
    "                        CanonicalModel.role_canonical_interpretation[role_name_str].append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main function for creating the canonical model.\n",
    "\n",
    "    Args:\n",
    "        onto_dir (str): a string pointing to the directory where the ontology is stored.\n",
    "\n",
    "    Returns:\n",
    "        canmodel (CanonicalModel): returns a variable containing the canonical model. \n",
    "        \n",
    "        Attention: the interpretations of concept names and role names can also be accessed via class variables\n",
    "        from the CanonicalModel class.\n",
    "'''\n",
    "\n",
    "def create_canonical_model(onto_dir):\n",
    "\n",
    "    onto = get_ontology(onto_dir)\n",
    "    onto = onto.load()\n",
    "    gcas_iter = list(onto.general_class_axioms()) # Attention: this will not work unless the generator is converted into a list\n",
    "    concept_names_iter = list(onto.classes())\n",
    "    role_names_iter = list(onto.properties())\n",
    "    individuals_iter = list(onto.individuals())\n",
    "\n",
    "    #for concept in concept_names_iter:\n",
    "    #    concept.namespace = onto.ontology\n",
    "\n",
    "    #for role in role_names_iter:\n",
    "    #    role.namespace = onto.ontology\n",
    "\n",
    "    get_canonical_model_elements(concept_names_iter, role_names_iter, onto)\n",
    "\n",
    "    print('')\n",
    "    print('============================================================================')\n",
    "    print('')\n",
    "    print('Starting to reason.')\n",
    "    print('')\n",
    "\n",
    "    with onto:\n",
    "        sync_reasoner()\n",
    "        \n",
    "    #onto.save(\"inferences_goslimyeast.owl\")\n",
    "\n",
    "    gcas_iter = list(onto.general_class_axioms()) # Attention: this will not work unless the generator is converted into a list\n",
    "    concept_names_iter = list(onto.classes())\n",
    "    role_names_iter = list(onto.properties())\n",
    "    individuals_iter = list(onto.individuals())\n",
    "\n",
    "    print('')\n",
    "    print('============================================================================')\n",
    "    print('')\n",
    "    print('Done reasoning. Creating the canonical model.')\n",
    "    print('')\n",
    "    canmodel = CanonicalModel(CanonicalModelElements.concept_names, CanonicalModelElements.concept_intersections, CanonicalModelElements.concept_restrictions, CanonicalModelElements.all_concepts, role_names_iter)\n",
    "    print('============================================================================')\n",
    "    print('')\n",
    "    print('Concluded creating canonical model.')\n",
    "\n",
    "    return canmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the canonical model\n",
    "\n",
    "canmodel = create_canonical_model(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility functions for initializing\n",
    "the class EntityEmbedding. They\n",
    "allow us to access dictionaries\n",
    "containing indexes and canonical\n",
    "interpretation of concepts\n",
    "and roles as class.\n",
    "'''\n",
    "\n",
    "def get_concept_names_idx_dict(canmodel):\n",
    "   conceptnames_idx_dict = {concept_name: idx for idx, concept_name in enumerate(CanonicalModel.concept_canonical_interpretation.keys())}\n",
    "   return conceptnames_idx_dict\n",
    "\n",
    "def get_role_names_idx_dict(canmodel):\n",
    "    rolenames_idx_dict = {role_name: idx for idx, role_name in enumerate(CanonicalModel.role_canonical_interpretation.keys())}\n",
    "    return rolenames_idx_dict\n",
    "\n",
    "def get_entities_idx_dict(canmodel):\n",
    "    entities_idx_dict = {entity: idx for idx, entity in enumerate(canmodel.domain.keys())}\n",
    "    return entities_idx_dict\n",
    "\n",
    "def get_domain_dict(canmodel):\n",
    "    return canmodel.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção: a função mu está com complexidade alta devido aos for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for obtaining the positional \n",
    "embedding for each entity in the domain\n",
    "of the canonical interpretation.\n",
    "It represents the Mu Function from the\n",
    "paper.\n",
    "'''\n",
    "\n",
    "class EntityEmbedding:\n",
    "\n",
    "    # Dictionaries for storing the indices of concept names and role names, entities pairs, respectively\n",
    "    # Keys are strings and values are integers\n",
    "    \n",
    "    concept_names_idx_dict = get_concept_names_idx_dict(canmodel)\n",
    "    role_names_idx_dict = get_role_names_idx_dict(canmodel)\n",
    "    entities_idx_dict = get_entities_idx_dict(canmodel)\n",
    "\n",
    "    # Dictionaries accessing the canonical interpretation of concepts and roles\n",
    "    # Keys and values are strings\n",
    "    \n",
    "    concept_canonical_interpretation_dict = CanonicalModel.concept_canonical_interpretation\n",
    "    role_canonical_interpretation_dict = CanonicalModel.role_canonical_interpretation\n",
    "\n",
    "    # Dictionary storing the domain of the canonical model being embedded\n",
    "    # IMPORTANT: Keys are strings and values are CanonicalModelElements type objects\n",
    "    \n",
    "    domain_dict = get_domain_dict(canmodel)\n",
    "\n",
    "    # Dictionary for easy access to entity embeddings\n",
    "    # It is initialized with empty values, iteratively built by the .get_embedding_vector() method\n",
    "    # Key (str): Domain Entity / Value (np.array): EntityEmbedding.embedding_vector\n",
    "\n",
    "    entity_entityvector_dict = dict.fromkeys(domain_dict.keys())\n",
    "\n",
    "    def __init__(self, entity_name, emb_dim):\n",
    "        self.name = entity_name\n",
    "        self.emb_dim = emb_dim\n",
    "        self.in_interpretation_of = []\n",
    "        self.embedding_vector = self.get_embedding_vector()\n",
    "\n",
    "    def get_embedding_vector(self):\n",
    "        \n",
    "        embedding_vector = np.zeros((self.emb_dim,))\n",
    "        EntityEmbedding.entity_entityvector_dict[self.name] = []\n",
    "\n",
    "        # Applies the embedding function to the concept names portion of the definition\n",
    "\n",
    "        for concept_name in EntityEmbedding.concept_canonical_interpretation_dict:\n",
    "            concept_name_idx = EntityEmbedding.concept_names_idx_dict[concept_name]\n",
    "        \n",
    "            if self.name in EntityEmbedding.concept_canonical_interpretation_dict[concept_name]:\n",
    "                embedding_vector[concept_name_idx] = 1\n",
    "                self.in_interpretation_of.append(concept_name)\n",
    "\n",
    "        # Applies the embedding function to the role names portion of the definition\n",
    "\n",
    "        for role_name in EntityEmbedding.role_canonical_interpretation_dict:\n",
    "            \n",
    "            role_name_idx = len(EntityEmbedding.concept_names_idx_dict) + (EntityEmbedding.role_names_idx_dict[role_name] * len(EntityEmbedding.entities_idx_dict))\n",
    "            role_name_caninterp = EntityEmbedding.role_canonical_interpretation_dict[role_name]\n",
    "\n",
    "            for pair in role_name_caninterp:\n",
    "\n",
    "                entity_2 = pair[1]\n",
    "\n",
    "                if (self.name, entity_2) == pair:\n",
    "                    entity_2_idx = EntityEmbedding.entities_idx_dict[entity_2]\n",
    "                    final_role_entity_pair_idx = role_name_idx + entity_2_idx\n",
    "                    embedding_vector[final_role_entity_pair_idx] = 1\n",
    "\n",
    "        # EntityEmbedding.entity_entityvector_dict[self.name].append(embedding_vector)\n",
    "        EntityEmbedding.entity_entityvector_dict[self.name] = embedding_vector\n",
    "\n",
    "        return embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for creating the binary vectors representing\n",
    "each element of the domain of the canonical interpretation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int/float): the number of dimensions of the embedding space.\n",
    "\n",
    "    Returns:\n",
    "        embedded_entities (list): a list containing all embeddings of the entities\n",
    "                                  in the domain. \n",
    "    \n",
    "    The embedded_entities are also available in the dictionary EntityEmbeddings.entity_entityvector_dict\n",
    "'''\n",
    "\n",
    "def get_domain_embeddings(emb_dim):\n",
    "\n",
    "    embedded_entities = []\n",
    "    counter = 0\n",
    "\n",
    "   # The entities in the domain are strings\n",
    "    \n",
    "    for entity_name in EntityEmbedding.domain_dict:\n",
    "       embedded_entity = EntityEmbedding(entity_name, emb_dim)\n",
    "       embedded_entities.append(embedded_entity)\n",
    "       counter += 1\n",
    "       \n",
    "       if counter % 1000 == 0:\n",
    "           print(counter)\n",
    "       \n",
    "    return embedded_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Final class for creating the dataset.\n",
    "\n",
    "Inputs: concept or role names, generated\n",
    "embeddings for entities in the domain of\n",
    "the canonical model.\n",
    "\n",
    "Outputs: geometrical interpretation of\n",
    "concepts and role names, represented\n",
    "by vertices defining a region.\n",
    "\n",
    "One can access the GeometricInterpretation\n",
    "objects either as elements in a list, or as\n",
    "values in a class variable dictionary.\n",
    "'''\n",
    "\n",
    "class GeometricInterpretation:\n",
    "\n",
    "    concept_geointerps_dict = dict.fromkeys(CanonicalModel.concept_canonical_interpretation.keys())\n",
    "    role_geointerps_dict = dict.fromkeys(CanonicalModel.role_canonical_interpretation.keys())\n",
    "\n",
    "    def __init__(self, name, emb_dim):\n",
    "        self.name = name\n",
    "        self.emb_dim = emb_dim\n",
    "        self.vertices = []\n",
    "        self.centroid = None\n",
    "        self.bounding_box_vertices = None\n",
    "\n",
    "    def get_centroid_naive(self):\n",
    "        if len(self.vertices) == 0 and self.name in self.concept_geointerps_dict.keys():\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) == 0 and self.name in self.role_geointerps_dict.keys():\n",
    "            centroid = np.zeros((self.emb_dim * 2,)) # The centroid for the regions needs to be doubled due to the concat operation\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) > 0 and self.name in self.concept_geointerps_dict.keys():\n",
    "            n = len(self.vertices)\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            matrix = np.vstack(self.vertices)\n",
    "            centroid = 1/n * np.sum(matrix, axis=0)\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) > 0 and self.name in self.role_geointerps_dict.keys():\n",
    "            n = len(self.vertices)\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            matrix = np.vstack(self.vertices)\n",
    "            centroid = 1/n * np.sum(matrix, axis=0)\n",
    "            return centroid\n",
    "\n",
    "    def get_bounding_box_vertices(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There has to be a more efficient way of doing the creating of geometric interpretations for concepts and roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(emb_dim, concept_name_idx_dict, role_name_idx_dict, domain_idx_dict):\n",
    "\n",
    "    index_dict = {k: None for k in range(emb_dim)}\n",
    "\n",
    "    for k,v in concept_name_idx_dict.items():\n",
    "\n",
    "        index_dict[v] = k\n",
    "\n",
    "    for role in role_name_idx_dict:\n",
    "        role_init_idx = len(concept_name_idx_dict) + (role_name_idx_dict[role] * len(domain_idx_dict))\n",
    "\n",
    "        for entity in domain_idx_dict:\n",
    "            entity_init_idx = domain_idx_dict[entity]\n",
    "            final_role_entity_pair_idx = role_init_idx + entity_init_idx\n",
    "            index_dict[final_role_entity_pair_idx] = (role, entity)\n",
    "        \n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faithful_concept_geometric_interps(concept_names_interps, domain_embeddings_list, entity_dims_index_dict, emb_dim, canmodel: CanonicalModel):\n",
    "\n",
    "    faithful_concept_geometric_interps = []\n",
    "\n",
    "    for concept_name in concept_names_interps.keys():\n",
    "        concept_name = GeometricInterpretation(concept_name, emb_dim)\n",
    "\n",
    "        for embedding in domain_embeddings_list:\n",
    "            if concept_name.name in embedding.in_interpretation_of:\n",
    "                concept_name.vertices.append(embedding.embedding_vector)\n",
    "            \n",
    "        GeometricInterpretation.concept_geointerps_dict[concept_name.name] = concept_name\n",
    "        concept_name.centroid = concept_name.get_centroid_naive()\n",
    "        \n",
    "        faithful_concept_geometric_interps.append(concept_name)\n",
    "\n",
    "    return faithful_concept_geometric_interps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faithful_role_geometric_interps(role_names_interps, entity_embeddings_list, entity_dims_index_dict, emb_dim, canmodel: CanonicalModel):\n",
    "    \n",
    "    faithful_role_geometric_interps = []\n",
    "    idx_entity_dict = entity_dims_index_dict\n",
    "    #entity_idx_dict = {v: k for k,v in entity_dims_index_dict}\n",
    "\n",
    "    relevant_idxs = len(canmodel.concept_names_dict)-1\n",
    "\n",
    "    for role_name in role_names_interps.keys():\n",
    "        role_name_str = role_name\n",
    "        role_name = GeometricInterpretation(role_name_str, emb_dim)\n",
    "\n",
    "        for entity in entity_embeddings_list:\n",
    "\n",
    "            onehot_idx_list = np.where(entity.embedding_vector == 1)[0]\n",
    "            #print(f'This is the entity: {entity} and this is the onehot_idx_list: {onehot_idx_list}')\n",
    "\n",
    "            for idx in onehot_idx_list: # I could just look at the TRULY relevant indexes\n",
    "                if idx > relevant_idxs:\n",
    "                    role_entity_pair = idx_entity_dict[idx]\n",
    "                    r_name_str = role_entity_pair[0]\n",
    "                    e_name_str = role_entity_pair[1]\n",
    "\n",
    "                    if r_name_str == role_name_str:\n",
    "                        e_embedding = EntityEmbedding.entity_entityvector_dict[e_name_str]\n",
    "                        role_name.vertices.append(np.concatenate((entity.embedding_vector, e_embedding)))\n",
    "\n",
    "        GeometricInterpretation.role_geointerps_dict[role_name_str] = role_name\n",
    "        role_name.centroid = role_name.get_centroid_naive()\n",
    "        faithful_role_geometric_interps.append(role_name)\n",
    "\n",
    "    return faithful_role_geometric_interps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tbox_embeddings(canonical_model: CanonicalModel):\n",
    "\n",
    "    domain = canonical_model.domain # Keys are strings and values are CanonicalModelElements type objects\n",
    "    concept_names_interps = canonical_model.concept_canonical_interpretation # Keys are strings and values are lists of strings.\n",
    "    role_names_interps = canonical_model.role_canonical_interpretation # Keys are strings and values are lists of tuples. Tuples are of form ('C', 'D'), with C and D strings.\n",
    "\n",
    "    EMB_DIM = len(concept_names_interps) + len(role_names_interps) * len(domain)\n",
    "\n",
    "    print('================EMBEDDING DIMENSION================')\n",
    "    print(f'Concept Name dimensions: {len(concept_names_interps)}')\n",
    "    print(f'The number of role names is: {len(role_names_interps)}')\n",
    "    print(f'The size of the domain is: {len(domain)}')\n",
    "    print(f'Role names dimensions: {len(role_names_interps) * len(domain)}')\n",
    "    print('===================================================')\n",
    "    print('')\n",
    "    print(f'Final embedding dimension: {EMB_DIM}')\n",
    "    print(f'The final dimension for role regions is: {EMB_DIM * 2}')\n",
    "\n",
    "    domain_embeddings_list = get_domain_embeddings(EMB_DIM)\n",
    "    \n",
    "    concept_names_ordering = EntityEmbedding.concept_names_idx_dict\n",
    "    role_names_ordering = EntityEmbedding.role_names_idx_dict\n",
    "    entities_ordering = EntityEmbedding.entities_idx_dict\n",
    "    \n",
    "    print('')\n",
    "    print('===============FINISHED EMBEDDINGS===============')\n",
    "    print(f'There are {len(domain_embeddings_list)} vector embeddings.')\n",
    "    print('')\n",
    "\n",
    "    index_finder_dict = index_finder(EMB_DIM, concept_names_ordering, role_names_ordering, entities_ordering)\n",
    "\n",
    "    faithful_concept_geometric_interps = get_faithful_concept_geometric_interps(concept_names_interps, domain_embeddings_list, index_finder_dict, EMB_DIM, canonical_model)\n",
    "\n",
    "    print('============FINISHED INTERPS CONCEPT=============')\n",
    "    print(f'There are {len(faithful_concept_geometric_interps)} regions for concept names.')\n",
    "    print('')\n",
    "\n",
    "    faithful_role_geometric_interps = get_faithful_role_geometric_interps(role_names_interps, domain_embeddings_list, index_finder_dict, EMB_DIM, canonical_model)\n",
    "\n",
    "    print('=============FINISHED INTERPS ROLES==============')\n",
    "    print(f'There are {len(faithful_role_geometric_interps)} regions for role names.')\n",
    "    print('')\n",
    "\n",
    "    return domain_embeddings_list, faithful_concept_geometric_interps, faithful_role_geometric_interps, index_finder_dict # Returns the faithful geometric interpretations for concepts and roles as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_embeddings, concept_geointerps, role_geointerps, idx_finder_dict = create_tbox_embeddings(canmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for creating the pre-split dataset containing facts from the ontology.\n",
    "Distinguishes between concept assertions and role assertions.\n",
    "\n",
    "\n",
    "    Args: ontology_dir (str): the directory from the ontology\n",
    "          concept_geointerps_dict (dict): the geometrical interpretations for concepts generated by create_tbox_embeddings()\n",
    "          role_geointerps_dict (dict): the geometrical interpretations for roles generated by create_tbox_embeddings()\n",
    "\n",
    "    Returns:\n",
    "          X_concepts (np.array): A dataframe with columns 'Concept', 'Entity', 'y_true' (equivalent to concept.centroid())\n",
    "          X_roles (np.array): A dataframe with columns 'SubjectEntity', 'Role', 'ObjectEntity', 'y_true' (equivalent to role.centroid())\n",
    "          y_concepts (np.array):\n",
    "          y_roles (np.array):\n",
    "          vocabulary_dict (dict): A vocabulary with key (int): value (str) for entities in the domain.\n",
    "'''\n",
    "\n",
    "def get_abox_dataset(ontology_dir: str, concept_geointerps_dict: dict, role_geointerps_dict: dict, concept_to_idx: dict, role_to_idx: dict):\n",
    "    \n",
    "    ontology = get_ontology(ontology_dir)\n",
    "    ontology = ontology.load()\n",
    "    \n",
    "    X_concepts = []\n",
    "    X_roles = []\n",
    "    y_concepts = []\n",
    "    y_roles = []\n",
    "\n",
    "    entities = [entity.name for entity in list(ontology.individuals())]\n",
    "    \n",
    "    concept_to_idx_vocab = concept_to_idx\n",
    "    idx_to_concept_vocab = {value: key for key, value in concept_to_idx_vocab.items()}\n",
    "\n",
    "    role_to_idx_vocab = role_to_idx\n",
    "    idx_to_role_vocab = {value: key for key, value in role_to_idx_vocab.items()}\n",
    "    \n",
    "    entity_to_idx_vocab = {value: index for index, value in enumerate(entities)}\n",
    "    idx_to_entity_vocab = {value: key for key, value in entity_to_idx_vocab.items()}\n",
    "\n",
    "    for individual in list(ontology.individuals()):\n",
    "\n",
    "        # all_facts = individual.INDIRECT_is_a # Is this actually getting all assertions?\n",
    "        all_facts = individual.is_a\n",
    "\n",
    "        for concept in all_facts:\n",
    "            if type(concept) == ThingClass:\n",
    "                concept = concept_geointerps_dict[concept.name]\n",
    "                fact = np.array([concept_to_idx_vocab[concept.name], entity_to_idx_vocab[individual.name]])\n",
    "                y_label = np.array(concept.centroid)\n",
    "                X_concepts.append(fact)\n",
    "                y_concepts.append(y_label)\n",
    "                \n",
    "            elif type(concept) == And:\n",
    "                print('And') # remove print statement\n",
    "                concept1 = concept_geointerps_dict[concept.Classes[0].name]\n",
    "                concept2 = concept_geointerps_dict[concept.Classes[1].name]\n",
    "                concept_name = 'And_' + ''.join(sorted(concept1.name + concept2.name))\n",
    "                fact = np.array([concept_to_idx_vocab[concept_name], entity_to_idx_vocab[individual.name]])\n",
    "                y_label = np.array((concept1.centroid + concept2.centroid)/2) # The golden label for an intersection is just the average of the centroid of the two regions\n",
    "                X_concepts.append(fact)\n",
    "                y_concepts.append(y_label)\n",
    "            \n",
    "            elif type(concept) == Restriction:\n",
    "                print('restriction') # remove print statement\n",
    "                concept = concept_geointerps_dict['exists_' + concept.property.name + '.' + concept.value.name]\n",
    "                fact = np.array([concept_to_idx_vocab[concept.name], entity_to_idx_vocab[individual.name]])\n",
    "                y_label = np.array(concept.centroid)\n",
    "                X_concepts.append(fact)\n",
    "                y_concepts.append(y_label)\n",
    "\n",
    "        relevant_roles = individual.get_properties()\n",
    "        individual_name = individual.name\n",
    "\n",
    "        for role in relevant_roles:\n",
    "            role_geo = role_geointerps_dict[role.name]\n",
    "            subject_list = role[individual] # This syntax is from the owlready2 library\n",
    "            for subject in subject_list:\n",
    "                fact = np.array([entity_to_idx_vocab[individual.name], role_to_idx_vocab[role.name], entity_to_idx_vocab[subject.name]])\n",
    "                X_roles.append(fact)\n",
    "                y_label = y_roles.append(np.array(role_geo.centroid))\n",
    "\n",
    "    return np.array(X_concepts), np.array(X_roles), np.array(y_concepts), np.array(y_roles), entity_to_idx_vocab, idx_to_entity_vocab, concept_to_idx_vocab, idx_to_concept_vocab, role_to_idx_vocab, idx_to_role_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concepts, X_roles, y_concepts, y_roles, entity_to_idx_vocab, idx_to_entity_vocab, concept_to_idx_vocab, idx_to_concept_vocab, role_to_idx_vocab, idx_to_role_vocab = get_abox_dataset(dir,\n",
    "                                                                                                                                                                                        GeometricInterpretation.concept_geointerps_dict,\n",
    "                                                                                                                                                                                        GeometricInterpretation.role_geointerps_dict,\n",
    "                                                                                                                                                                                        EntityEmbedding.concept_names_idx_dict,\n",
    "                                                                                                                                                                                        EntityEmbedding.role_names_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.X = torch.tensor(data, dtype=torch.long)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].long(), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE_PROPORTION = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "ConceptDataset = OntologyDataset(X_concepts, y_concepts)\n",
    "\n",
    "dataset_size = len(ConceptDataset)\n",
    "train_size = int(TRAIN_SIZE_PROPORTION * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "trainConceptDataset, testConceptDataset = torch.utils.data.random_split(ConceptDataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "RoleDataset = OntologyDataset(X_roles, y_roles)\n",
    "\n",
    "dataset_size = len(RoleDataset)\n",
    "train_size = int(TRAIN_SIZE_PROPORTION * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "trainRoleDataset, testRoleDataset = torch.utils.data.random_split(RoleDataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ConceptDataLoader = DataLoader(trainConceptDataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "test_ConceptDataLoader = DataLoader(testConceptDataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_RoleDataLoader = DataLoader(trainRoleDataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "test_RoleDataLoader = DataLoader(testRoleDataset, batch_size = BATCH_SIZE, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
