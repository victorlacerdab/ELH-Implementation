{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import owlready2 as owl\n",
    "from owlready2 import *\n",
    "owlready2.reasoning.JAVA_MEMORY = 200000\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/goslimyeast.xml.owl'\n",
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/galennorm.xml.owl'\n",
    "# dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/gonorm.xml.owl'\n",
    "# dir = '/Users/victorlacerda/Desktop/NormalizedOntologies/testontologies/toyontology.owl'\n",
    "# dir = '/Users/victorlacerda/Desktop/NormalizedOntologies/testontologies/toyrelation.owl'\n",
    "dir = '/Users/victorlacerda/Documents/VSCode/ELHFaithfulness/NormalizedOntologies/family_ontology.owl'\n",
    "# dir = '/Users/victorlacerda/Desktop/NormalizedOntologies/testontologies/dbpedia15k.owl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTRICT_LANGUAGE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class for creating entities to\n",
    "populate the creation of the\n",
    "canonical models.\n",
    "\n",
    "The .name attribute is used to\n",
    "create a single representation\n",
    "for concepts like A and B / \n",
    "B and A, as they are the same.\n",
    "'''\n",
    "\n",
    "class CanonicalModelElements:\n",
    "\n",
    "    concept_names = {}\n",
    "    concept_intersections = {}\n",
    "    concept_restrictions = {}\n",
    "    all_concepts = {}\n",
    "\n",
    "    def __init__(self, concept):\n",
    "        self.concept = concept\n",
    "        self.name = self.get_name()\n",
    "        self.get_element_dict()\n",
    "\n",
    "    def get_name(self):\n",
    "        \n",
    "        if type(self.concept) == ThingClass:\n",
    "            return self.concept.name\n",
    "\n",
    "        elif type(self.concept) == Restriction:\n",
    "            return 'exists_' + self.concept.property.name + '.' + self.concept.value.name\n",
    "        \n",
    "        else:\n",
    "            return 'And_' + ''.join(sorted(self.concept.Classes[0].name + self.concept.Classes[1].name)) # The name is sorted to avoid that (e.g) (A \\and B) and (B \\and A) are treated as different concepts\n",
    "        \n",
    "    def get_element_dict(self):\n",
    "\n",
    "        if type(self.concept) == ThingClass:\n",
    "            CanonicalModelElements.concept_names[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self\n",
    "\n",
    "        elif type(self.concept) == Restriction:\n",
    "            CanonicalModelElements.concept_restrictions[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self\n",
    "\n",
    "        elif type(self.concept) == And:\n",
    "            CanonicalModelElements.concept_intersections[self.name] = self\n",
    "            CanonicalModelElements.all_concepts[self.name] = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canonical_model_elements(concept_names_iter, role_names_iter, ontology, restrict_language = True):\n",
    "    \n",
    "    onto = ontology\n",
    "    top = owl.Thing\n",
    "    #bottom = owl.Nothing\n",
    "\n",
    "    CanonicalModelElements(top)\n",
    "    #CanonicalModelElements(bottom)\n",
    "\n",
    "    for concept_name in concept_names_iter:\n",
    "        \n",
    "        CanonicalModelElements(concept_name)\n",
    "\n",
    "        if restrict_language == False:\n",
    "\n",
    "            for concept_name2 in concept_names_iter:\n",
    "        \n",
    "                with onto:\n",
    "                    gca = GeneralClassAxiom(concept_name & concept_name2)\n",
    "                    gca.is_a.append(concept_name & concept_name2)\n",
    "            \n",
    "                CanonicalModelElements(gca.left_side)\n",
    "\n",
    "    print('')\n",
    "    print('===========================================================================================================')\n",
    "    print('All Concept Names and Concept Intersections have been preprocessed for the creation of the canonical model.')\n",
    "    print('===========================================================================================================')\n",
    "\n",
    "    concept_names_iter.append(top)\n",
    "    #concept_names_iter.append(bottom)\n",
    "\n",
    "    if restrict_language == False:\n",
    "\n",
    "        for role_name in role_names_iter:\n",
    "            for concept_name in concept_names_iter:\n",
    "                with onto:\n",
    "                    gca = GeneralClassAxiom(role_name.some(concept_name))\n",
    "                    gca.is_a.append(role_name.some(concept_name))\n",
    "\n",
    "                CanonicalModelElements(gca.left_side)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for role_name in role_names_iter:\n",
    "            with onto:\n",
    "                gca = GeneralClassAxiom(role_name.some(owl.Thing))\n",
    "                gca.is_a.append(role_name.some(owl.Thing))\n",
    "\n",
    "                CanonicalModelElements(gca.left_side)\n",
    "            \n",
    "    print('')\n",
    "    print('All restrictions have been preprocessed for the creation of the canonical model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The main class for creating the canonical model for the ontology.\n",
    "\n",
    "The canonical model is stored in dictionaries available as class variables 'concept_canonical_interpretation'\n",
    "and 'role_canonical_interpretation'. \n",
    "\n",
    "Args:\n",
    "    concept_names_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    concept_intersection_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    concept_restrictions_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    all_concepts_dict: a dictionary stored in the CanonicalModelElement class.\n",
    "    role_names_iter (list): a list containing all role names in the loaded ontology.\n",
    "'''\n",
    "\n",
    "class CanonicalModel:\n",
    "\n",
    "    concept_canonical_interpretation = {}\n",
    "    role_canonical_interpretation = {}\n",
    "\n",
    "    def __init__(self, concept_names_dict, concept_intersections_dict, concept_restrictions_dict, all_concepts_dict, role_names_iter):\n",
    "        \n",
    "        self.domain = all_concepts_dict\n",
    "        self.concept_names_dict = concept_names_dict\n",
    "        self.concept_restrictions_dict = concept_restrictions_dict\n",
    "        self.concept_intersections_dict = concept_intersections_dict\n",
    "\n",
    "        self.role_names_iter = role_names_iter\n",
    "\n",
    "        self.concept_canonical_interp = self.get_concept_name_caninterp() # These are only used to build the concept_canonical_interpretation and role_canonical_interpretation class attributes\n",
    "        self.role_canonical_interp = self.get_role_name_caninterp()       # The functions do not return anything, they just update their corresponding class variables \n",
    "\n",
    "    def get_concept_name_caninterp(self):\n",
    "\n",
    "        # The variable concept is a string containing the name of an element of the domain of the canonical model\n",
    "        # The key to the concept_names_dict variable corresponds to concept.name\n",
    "        # This name can be used to access the concept in owlready2's format\n",
    "\n",
    "        for concept in self.concept_names_dict.keys():\n",
    "\n",
    "            CanonicalModel.concept_canonical_interpretation[concept] = []\n",
    "            superclasses = self.domain[concept].concept.ancestors(include_self=True, include_constructs=True) # The self.domain[concept] is used to access the CanonicalModelElements type of object,\n",
    "                                                                                                               # and the attribute .concept is used to access the concept in owlready2 format                                                            \n",
    "            for superclass in superclasses:\n",
    "\n",
    "                if type(superclass) == ThingClass:\n",
    "                    CanonicalModel.concept_canonical_interpretation[concept].append(superclass.name)\n",
    "\n",
    "                elif type(superclass) == Restriction:\n",
    "                    CanonicalModel.concept_canonical_interpretation[concept].append('exists_' + superclass.property.name + '.' + superclass.value.name)\n",
    "\n",
    "                elif type(superclass) == And:\n",
    "                    if 'And_' + ''.join(sorted(superclass.Classes[0].name + superclass.Classes[1].name)) in CanonicalModel.concept_canonical_interpretation[concept]:\n",
    "                        pass\n",
    "                    else:\n",
    "                        CanonicalModel.concept_canonical_interpretation[concept].append('And_' + ''.join(sorted(superclass.Classes[0].name + superclass.Classes[1].name)))\n",
    "\n",
    "            \n",
    "    def get_role_name_caninterp(self):\n",
    "\n",
    "        # Initialize the dictionary storing the canonical interpretation of roles\n",
    "\n",
    "        for role_name in self.role_names_iter:\n",
    "\n",
    "            role_name_str = role_name.name # Accesses the property type object's name as a string\n",
    "            CanonicalModel.role_canonical_interpretation[role_name_str] = []\n",
    "\n",
    "        # First case from Definition 10\n",
    "                                \n",
    "        for role_name in self.role_names_iter:\n",
    "\n",
    "            superroles = role_name.ancestors(include_self=True)\n",
    "\n",
    "            for superrole in superroles:\n",
    "                for restriction_name, restriction_concept in self.concept_restrictions_dict.items():\n",
    "\n",
    "                    if superrole == restriction_concept.concept.property:\n",
    "                        concept_name_str = restriction_concept.concept.value.name\n",
    "                        pair = (restriction_name, concept_name_str)\n",
    "                        CanonicalModel.role_canonical_interpretation[role_name.name].append(pair)\n",
    "                        \n",
    "        \n",
    "        # Second case from Definition 10\n",
    "\n",
    "        for restriction_name in self.concept_restrictions_dict.keys(): # Where restriction_name denotes a \\exists r.B type of concept 'exists_' + self.concept.property.name + '.' + self.concept.value.name\n",
    "\n",
    "            #print(f'Restriction name init for loop: {restriction_name}')\n",
    "            restriction_concept = self.concept_restrictions_dict[restriction_name].concept\n",
    "            c_B = self.concept_restrictions_dict[restriction_name].concept.value.name\n",
    "            #print(f'c_B: {c_B}\\n')\n",
    "\n",
    "            superclasses = restriction_concept.ancestors(include_self=True, include_constructs=False)\n",
    "\n",
    "            for superclass in superclasses:\n",
    "\n",
    "                super_superclasses = superclass.ancestors(include_self=True, include_constructs=True)\n",
    "\n",
    "                for super_superclass in super_superclasses:\n",
    "                    if type(super_superclass) == ThingClass:\n",
    "                        c_D = super_superclass.name\n",
    "                        CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n",
    "\n",
    "                    elif type(super_superclass) == Restriction:\n",
    "                        c_D = 'exists_' + super_superclass.property.name + '.' + super_superclass.value.name\n",
    "                        CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n",
    "\n",
    "                    elif type(super_superclass) == And:\n",
    "                        c_D = 'And_' + ''.join(sorted(super_superclass.Classes[0].name + super_superclass.Classes[1].name))\n",
    "                        CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n",
    "                    \n",
    "        \n",
    "            if role_name_str in restriction_name:\n",
    "\n",
    "                #print(f'It is true that {role_name_str} is in {restriction_name}.')\n",
    "                    \n",
    "                superclasses = self.domain[restriction_name].concept.ancestors(include_self=True, include_constructs=False) # Include_constructs is turned to false due to the definition of canonical model\n",
    "\n",
    "                #print(f'These are the superclasses of the restriction_name {restriction_name}:\" {superclasses}')\n",
    "\n",
    "                for superclass in superclasses:\n",
    "                    super_superclasses = superclass.ancestors(include_self=True, include_constructs=True)\n",
    "\n",
    "                    for super_superclass in super_superclasses:\n",
    "\n",
    "                        if type(super_superclass) == ThingClass:\n",
    "                            c_D = super_superclass.name\n",
    "                            CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n",
    "\n",
    "                        elif type(super_superclass) == Restriction:\n",
    "                            c_D = 'exists_' + super_superclass.property.name + '.' + super_superclass.value.name\n",
    "                            CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n",
    "\n",
    "                        elif type(super_superclass) == And:\n",
    "                            c_D = 'And_' + ''.join(sorted(super_superclass.Classes[0].name + super_superclass.Classes[1].name))\n",
    "                            CanonicalModel.role_canonical_interpretation[role_name_str].append((c_D, c_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main function for creating the canonical model.\n",
    "\n",
    "    Args:\n",
    "        onto_dir (str): a string pointing to the directory where the ontology is stored.\n",
    "\n",
    "    Returns:\n",
    "        canmodel (CanonicalModel): returns a variable containing the canonical model. \n",
    "        \n",
    "        Attention: the interpretations of concept names and role names can also be accessed via class variables\n",
    "        from the CanonicalModel class.\n",
    "'''\n",
    "\n",
    "def create_canonical_model(onto_dir, restrict_language_flag):\n",
    "\n",
    "    onto = get_ontology(onto_dir)\n",
    "    onto = onto.load()\n",
    "\n",
    "    individuals_iter = list(onto.individuals())\n",
    "    gcas_iter = list(onto.general_class_axioms()) # Attention: this will not work unless the generator is converted into a list\n",
    "    concept_names_iter = list(onto.classes())\n",
    "    role_names_iter = list(onto.properties())\n",
    "\n",
    "    get_canonical_model_elements(concept_names_iter, role_names_iter, onto, restrict_language_flag)\n",
    "\n",
    "    print('============================================================================')\n",
    "    print('Starting to reason.\\n')\n",
    "\n",
    "    with onto:\n",
    "        sync_reasoner()\n",
    "        \n",
    "    #onto.save(\"inferences_goslimyeast.owl\")\n",
    "\n",
    "    gcas_iter = list(onto.general_class_axioms()) # Attention: this will not work unless the generator is converted into a list\n",
    "    concept_names_iter = list(onto.classes())\n",
    "    role_names_iter = list(onto.properties())\n",
    "    individuals_iter = list(onto.individuals())\n",
    "\n",
    "    print('')\n",
    "    print('============================================================================')\n",
    "    print('Done reasoning. Creating the canonical model.')\n",
    "    canmodel = CanonicalModel(CanonicalModelElements.concept_names, CanonicalModelElements.concept_intersections, CanonicalModelElements.concept_restrictions, CanonicalModelElements.all_concepts, role_names_iter)\n",
    "    print('============================================================================\\n')\n",
    "    print('Concluded creating canonical model.')\n",
    "\n",
    "    return canmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================================================\n",
      "All Concept Names and Concept Intersections have been preprocessed for the creation of the canonical model.\n",
      "===========================================================================================================\n",
      "\n",
      "All restrictions have been preprocessed for the creation of the canonical model.\n",
      "============================================================================\n",
      "Starting to reason.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx200000M -cp /opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/owlready2/hermit:/opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/owlready2/hermit/HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:////var/folders/wg/g5861gcs6k5d3rbq_rncztjw0000gn/T/tmp66jf7l1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "Done reasoning. Creating the canonical model.\n",
      "============================================================================\n",
      "\n",
      "Concluded creating canonical model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * HermiT took 0.6325712203979492 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "# Instantiates the canonical model\n",
    "\n",
    "canmodel = create_canonical_model(dir, RESTRICT_LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção: a função mu está com complexidade alta devido aos for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility functions for initializing\n",
    "the class EntityEmbedding. They\n",
    "allow us to access dictionaries\n",
    "containing indexes and canonical\n",
    "interpretation of concepts\n",
    "and roles as class.\n",
    "'''\n",
    "\n",
    "def get_concept_names_idx_dict(canmodel):\n",
    "   conceptnames_idx_dict = {concept_name: idx for idx, concept_name in enumerate(CanonicalModel.concept_canonical_interpretation.keys())}\n",
    "   return conceptnames_idx_dict\n",
    "\n",
    "def get_role_names_idx_dict(canmodel):\n",
    "    rolenames_idx_dict = {role_name: idx for idx, role_name in enumerate(CanonicalModel.role_canonical_interpretation.keys())}\n",
    "    return rolenames_idx_dict\n",
    "\n",
    "def get_entities_idx_dict(canmodel):\n",
    "    entities_idx_dict = {entity: idx for idx, entity in enumerate(canmodel.domain.keys())}\n",
    "    return entities_idx_dict\n",
    "\n",
    "def get_domain_dict(canmodel):\n",
    "    return canmodel.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for obtaining the positional \n",
    "embedding for each entity in the domain\n",
    "of the canonical interpretation.\n",
    "It represents the Mu Function from the\n",
    "paper.\n",
    "'''\n",
    "\n",
    "class EntityEmbedding:\n",
    "\n",
    "    # Dictionaries for storing the indices of concept names and role names, entities pairs, respectively\n",
    "    # Keys are strings and values are integers\n",
    "    \n",
    "    concept_names_idx_dict = get_concept_names_idx_dict(canmodel)\n",
    "    role_names_idx_dict = get_role_names_idx_dict(canmodel)\n",
    "    entities_idx_dict = get_entities_idx_dict(canmodel)\n",
    "\n",
    "    # Dictionaries accessing the canonical interpretation of concepts and roles\n",
    "    # Keys and values are strings\n",
    "    \n",
    "    concept_canonical_interpretation_dict = CanonicalModel.concept_canonical_interpretation\n",
    "    role_canonical_interpretation_dict = CanonicalModel.role_canonical_interpretation\n",
    "\n",
    "    # Dictionary storing the domain of the canonical model being embedded\n",
    "    # IMPORTANT: Keys are strings and values are CanonicalModelElements type objects\n",
    "    \n",
    "    domain_dict = get_domain_dict(canmodel)\n",
    "\n",
    "    # Dictionary for easy access to entity embeddings\n",
    "    # It is initialized with empty values, iteratively built by the .get_embedding_vector() method\n",
    "    # Key (str): Domain Entity / Value (np.array): EntityEmbedding.embedding_vector\n",
    "\n",
    "    entity_entityvector_dict = dict.fromkeys(domain_dict.keys())\n",
    "\n",
    "    def __init__(self, entity_name, emb_dim, restrict_language_flag, scale_factor):\n",
    "        self.name = entity_name\n",
    "        self.emb_dim = emb_dim\n",
    "        self.scale_factor = scale_factor\n",
    "        self.in_interpretation_of = []\n",
    "        self.restrict_language_flag = restrict_language_flag\n",
    "        self.embedding_vector = self.get_embedding_vector()\n",
    "\n",
    "    def get_embedding_vector(self):\n",
    "        \n",
    "        embedding_vector = np.zeros((self.emb_dim,))\n",
    "        EntityEmbedding.entity_entityvector_dict[self.name] = []\n",
    "\n",
    "        # Applies the embedding function to the concept names portion of the definition\n",
    "\n",
    "        for concept_name in EntityEmbedding.concept_canonical_interpretation_dict:\n",
    "            concept_name_idx = EntityEmbedding.concept_names_idx_dict[concept_name]\n",
    "        \n",
    "            if self.name in EntityEmbedding.concept_canonical_interpretation_dict[concept_name]:\n",
    "                embedding_vector[concept_name_idx] = 1 * self.scale_factor\n",
    "                self.in_interpretation_of.append(concept_name)\n",
    "\n",
    "        # Applies the embedding function to the role names portion of the definition\n",
    "                \n",
    "        #print(f'Now embedding the role section of entity {self.name}')\n",
    "\n",
    "        for role_name in EntityEmbedding.role_canonical_interpretation_dict:\n",
    "\n",
    "            if self.restrict_language_flag == False:\n",
    "            \n",
    "                role_name_idx = len(EntityEmbedding.concept_names_idx_dict) + (EntityEmbedding.role_names_idx_dict[role_name] * len(EntityEmbedding.entities_idx_dict)) # Entities dict indexes on the domain of the canonical model\n",
    "\n",
    "            else:\n",
    "\n",
    "                role_name_idx = len(EntityEmbedding.concept_names_idx_dict) + EntityEmbedding.role_names_idx_dict[role_name]\n",
    "            \n",
    "            #print(f'This is the role name {role_name}\\n This is the role_name_idx {role_name_idx}')\n",
    "\n",
    "            role_name_caninterp = EntityEmbedding.role_canonical_interpretation_dict[role_name]\n",
    "       \n",
    "            #print(f'This is the caninterp of {role_name}: {role_name_caninterp}.')\n",
    "\n",
    "            for pair in role_name_caninterp:\n",
    "                #print(f'The pair {pair} is in consideration.')\n",
    "\n",
    "                entity_2 = pair[1] # This is a string\n",
    "\n",
    "                if (self.name, entity_2) == pair:\n",
    "                    #print(f'!!!!!!!!!!!! The condition was triggered. !!!!!!!!!!!!')\n",
    "                    entity_2_idx = EntityEmbedding.entities_idx_dict[entity_2]\n",
    "                    #print(f'Index of entity_2: {entity_2_idx}')\n",
    "                    final_role_entity_pair_idx = role_name_idx + entity_2_idx\n",
    "                    #print(f'Final computed index for the {pair}: {final_role_entity_pair_idx}')\n",
    "                    embedding_vector[final_role_entity_pair_idx] = 1 * self.scale_factor\n",
    "\n",
    "        #print(f'========================================================\\n')\n",
    "        # EntityEmbedding.entity_entityvector_dict[self.name].append(embedding_vector)\n",
    "        EntityEmbedding.entity_entityvector_dict[self.name] = embedding_vector\n",
    "\n",
    "        return embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for creating the binary vectors representing\n",
    "each element of the domain of the canonical interpretation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int/float): the number of dimensions of the embedding space.\n",
    "\n",
    "    Returns:\n",
    "        embedded_entities (list): a list containing all embeddings of the entities\n",
    "                                  in the domain. \n",
    "    \n",
    "    The embedded_entities are also available in the dictionary EntityEmbeddings.entity_entityvector_dict\n",
    "'''\n",
    "\n",
    "def get_domain_embeddings(emb_dim, restrict_language_flag, scale_factor):\n",
    "\n",
    "    embedded_entities = []\n",
    "    counter = 0\n",
    "\n",
    "   # The entities in the domain are strings\n",
    "    \n",
    "    for entity_name in EntityEmbedding.domain_dict:\n",
    "       embedded_entity = EntityEmbedding(entity_name, emb_dim, restrict_language_flag, scale_factor)\n",
    "       embedded_entities.append(embedded_entity)\n",
    "       counter += 1\n",
    "       \n",
    "       if counter % 1000 == 0:\n",
    "           print(counter)\n",
    "       \n",
    "    return embedded_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Final class for creating the dataset.\n",
    "\n",
    "Inputs: concept or role names, generated\n",
    "embeddings for entities in the domain of\n",
    "the canonical model.\n",
    "\n",
    "Outputs: geometrical interpretation of\n",
    "concepts and role names, represented\n",
    "by vertices defining a region.\n",
    "\n",
    "One can access the GeometricInterpretation\n",
    "objects either as elements in a list, or as\n",
    "values in a class variable dictionary.\n",
    "'''\n",
    "\n",
    "class GeometricInterpretation:\n",
    "\n",
    "    concept_geointerps_dict = dict.fromkeys(CanonicalModel.concept_canonical_interpretation.keys())\n",
    "    role_geointerps_dict = dict.fromkeys(CanonicalModel.role_canonical_interpretation.keys())\n",
    "\n",
    "    def __init__(self, name, emb_dim):\n",
    "        self.name = name\n",
    "        self.emb_dim = emb_dim\n",
    "        self.vertices = []\n",
    "        self.centroid = None\n",
    "\n",
    "        if GeometricInterpretation.concept_geointerps_dict.get(name) is not None:\n",
    "            GeometricInterpretation.concept_geointerps_dict[name] = []\n",
    "\n",
    "    def get_centroid_naive(self):\n",
    "        if len(self.vertices) == 0 and self.name in self.concept_geointerps_dict.keys():\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) == 0 and self.name in self.role_geointerps_dict.keys():\n",
    "            centroid = np.zeros((self.emb_dim * 2,)) # The centroid for the regions needs to be doubled due to the concat operation\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) > 0 and self.name in self.concept_geointerps_dict.keys():\n",
    "            n = len(self.vertices)\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            matrix = np.vstack(self.vertices)\n",
    "            centroid = 1/n * np.sum(matrix, axis=0)\n",
    "            return centroid\n",
    "        \n",
    "        elif len(self.vertices) > 0 and self.name in self.role_geointerps_dict.keys():\n",
    "            n = len(self.vertices)\n",
    "            centroid = np.zeros((self.emb_dim,))\n",
    "            matrix = np.vstack(self.vertices)\n",
    "            centroid = 1/n * np.sum(matrix, axis=0)\n",
    "            return centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There has to be a more efficient way of doing the creating of geometric interpretations for concepts and roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(emb_dim, restrict_language_flag, concept_name_idx_dict, role_name_idx_dict, domain_idx_dict):\n",
    "\n",
    "    index_dict = {k: None for k in range(emb_dim)}\n",
    "\n",
    "    for k,v in concept_name_idx_dict.items():\n",
    "        index_dict[v] = k\n",
    "\n",
    "    if restrict_language_flag == False:\n",
    "\n",
    "        for role in role_name_idx_dict:\n",
    "            role_init_idx = len(concept_name_idx_dict) + (role_name_idx_dict[role] * len(domain_idx_dict))\n",
    "\n",
    "            for entity in domain_idx_dict:\n",
    "                entity_init_idx = domain_idx_dict[entity]\n",
    "                final_role_entity_pair_idx = role_init_idx + entity_init_idx\n",
    "                index_dict[final_role_entity_pair_idx] = (role, entity)\n",
    "\n",
    "    elif restrict_language_flag == True:\n",
    "\n",
    "        for role in role_name_idx_dict:\n",
    "            role_init_idx = len(concept_name_idx_dict) + (role_name_idx_dict[role] * len(domain_idx_dict))\n",
    "\n",
    "            for entity in domain_idx_dict:\n",
    "                entity_init_idx = domain_idx_dict[entity]\n",
    "                final_role_entity_pair_idx = role_init_idx + entity_init_idx\n",
    "                index_dict[final_role_entity_pair_idx] = (role, entity)\n",
    "       \n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faithful_concept_geometric_interps(concept_names_interps, domain_embeddings_list, entity_dims_index_dict, emb_dim, canmodel: CanonicalModel):\n",
    "\n",
    "    faithful_concept_geometric_interps = []\n",
    "\n",
    "    for concept_name in concept_names_interps.keys():\n",
    "        concept_name = GeometricInterpretation(concept_name, emb_dim)\n",
    "\n",
    "        for embedding in domain_embeddings_list:\n",
    "            if concept_name.name in embedding.in_interpretation_of:\n",
    "                concept_name.vertices.append(embedding.embedding_vector)\n",
    "            \n",
    "        GeometricInterpretation.concept_geointerps_dict[concept_name.name] = concept_name\n",
    "        concept_name.centroid = concept_name.get_centroid_naive()\n",
    "        \n",
    "        faithful_concept_geometric_interps.append(concept_name)\n",
    "\n",
    "    return faithful_concept_geometric_interps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faithful_role_geometric_interps(role_names_interps, entity_embeddings_list, entity_dims_index_dict, emb_dim, scaling_factor, canmodel: CanonicalModel):\n",
    "    \n",
    "    faithful_role_geometric_interps = []\n",
    "    idx_entity_dict = entity_dims_index_dict\n",
    "    #entity_idx_dict = {v: k for k,v in entity_dims_index_dict}\n",
    "\n",
    "    relevant_idxs = len(canmodel.concept_names_dict)\n",
    "\n",
    "    for role_name in role_names_interps.keys():\n",
    "        # print(f'This is the role in consideration: {role_name}')\n",
    "        role_name_str = role_name\n",
    "        role_name = GeometricInterpretation(role_name_str, emb_dim)\n",
    "\n",
    "        for entity in entity_embeddings_list:\n",
    "\n",
    "            onehot_idx_list = np.where(entity.embedding_vector == 1 * scaling_factor)[0]\n",
    "            # print(f'This is the entity: {entity.name} and this is the onehot_idx_list: {onehot_idx_list}')\n",
    "\n",
    "            for idx in onehot_idx_list: # I could just look at the TRULY relevant indexes\n",
    "                if idx >= relevant_idxs:\n",
    "                    # print(f'!!!!!!!!!!!!!! CONDITION TRIGGERED !!!!!!!!!!!!!!')\n",
    "                    role_entity_pair = idx_entity_dict[idx]\n",
    "                    # print(f'{role_entity_pair}')\n",
    "                    r_name_str = role_entity_pair[0]\n",
    "                    e_name_str = role_entity_pair[1]\n",
    "\n",
    "                    if r_name_str == role_name_str:\n",
    "                        e_embedding = EntityEmbedding.entity_entityvector_dict[e_name_str]\n",
    "                        role_name.vertices.append(np.concatenate((entity.embedding_vector, e_embedding)))\n",
    "\n",
    "        GeometricInterpretation.role_geointerps_dict[role_name_str] = role_name\n",
    "        role_name.centroid = role_name.get_centroid_naive()\n",
    "        faithful_role_geometric_interps.append(role_name)\n",
    "\n",
    "    return faithful_role_geometric_interps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default for the scale_factor is 1 to create binary vectors.\n",
    "\n",
    "def create_tbox_embeddings(canonical_model: CanonicalModel, restrict_language_flag=bool, scale_factor = 1):\n",
    "\n",
    "    domain = canonical_model.domain # Keys are strings and values are CanonicalModelElements type objects\n",
    "    concept_names_interps = canonical_model.concept_canonical_interpretation # Keys are strings and values are lists of strings.\n",
    "    role_names_interps = canonical_model.role_canonical_interpretation # Keys are strings and values are lists of tuples. Tuples are of form ('C', 'D'), with C and D strings.\n",
    "\n",
    "    SCALE_FACTOR = scale_factor\n",
    "    RESTRICT_LANGUAGE = restrict_language_flag\n",
    "    \n",
    "    if restrict_language_flag == False:\n",
    "\n",
    "        EMB_DIM = len(concept_names_interps) + len(role_names_interps) * len(domain)\n",
    "\n",
    "        print('================EMBEDDING DIMENSION================')\n",
    "        print(f'Concept Name dimensions: {len(concept_names_interps)}')\n",
    "        print(f'The number of role names is: {len(role_names_interps)}')\n",
    "        print(f'The size of the domain is: {len(domain)}')\n",
    "        print(f'Role names dimensions: {len(role_names_interps) * len(domain)}')\n",
    "        print('===================================================')\n",
    "        print('')\n",
    "        print(f'Final embedding dimension: {EMB_DIM}')\n",
    "        print(f'The final dimension for role regions is: {EMB_DIM * 2}')\n",
    "\n",
    "    else:\n",
    "\n",
    "        EMB_DIM = len(concept_names_interps) + len(role_names_interps) * len(domain)\n",
    "        \n",
    "        print('================EMBEDDING DIMENSION================')\n",
    "        print(f'Concept Name dimensions: {len(concept_names_interps)}')\n",
    "        print(f'The number of role names is: {len(role_names_interps)}')\n",
    "        print(f'The size of the domain is: {len(domain)}')\n",
    "        print(f'Role names dimensions: {len(role_names_interps)}')\n",
    "        print('===================================================')\n",
    "        print('')\n",
    "        print(f'Final embedding dimension: {EMB_DIM}')\n",
    "        print(f'The final dimension for role regions is: {EMB_DIM * 2}')\n",
    "\n",
    "\n",
    "    domain_embeddings_list = get_domain_embeddings(EMB_DIM, RESTRICT_LANGUAGE, SCALE_FACTOR) # This function initializes the vectors with 0 and one-hot encodes them according to \\mu\n",
    "    \n",
    "    concept_names_ordering = EntityEmbedding.concept_names_idx_dict\n",
    "    role_names_ordering = EntityEmbedding.role_names_idx_dict\n",
    "    entities_ordering = EntityEmbedding.entities_idx_dict\n",
    "    \n",
    "    print('')\n",
    "    print('===============FINISHED EMBEDDINGS===============')\n",
    "    print(f'There are {len(domain_embeddings_list)} vector embeddings.')\n",
    "    print('')\n",
    "\n",
    "    index_finder_dict = index_finder(EMB_DIM, RESTRICT_LANGUAGE, concept_names_ordering, role_names_ordering, entities_ordering)\n",
    "\n",
    "    faithful_concept_geometric_interps = get_faithful_concept_geometric_interps(concept_names_interps, domain_embeddings_list, index_finder_dict, EMB_DIM, canonical_model)\n",
    "\n",
    "    print('============FINISHED INTERPS CONCEPT=============')\n",
    "    print(f'There are {len(faithful_concept_geometric_interps)} regions for concept names.')\n",
    "    print('')\n",
    "\n",
    "    faithful_role_geometric_interps = get_faithful_role_geometric_interps(role_names_interps, domain_embeddings_list, index_finder_dict, EMB_DIM, SCALE_FACTOR, canonical_model)\n",
    "\n",
    "    print('=============FINISHED INTERPS ROLES==============')\n",
    "    print(f'There are {len(faithful_role_geometric_interps)} regions for role names.')\n",
    "    print('')\n",
    "\n",
    "    return domain_embeddings_list, faithful_concept_geometric_interps, faithful_role_geometric_interps, index_finder_dict, int(EMB_DIM), int(scale_factor) # Returns the faithful geometric interpretations for concepts and roles as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================EMBEDDING DIMENSION================\n",
      "Concept Name dimensions: 9\n",
      "The number of role names is: 5\n",
      "The size of the domain is: 90\n",
      "Role names dimensions: 450\n",
      "===================================================\n",
      "\n",
      "Final embedding dimension: 459\n",
      "The final dimension for role regions is: 918\n",
      "\n",
      "===============FINISHED EMBEDDINGS===============\n",
      "There are 90 vector embeddings.\n",
      "\n",
      "============FINISHED INTERPS CONCEPT=============\n",
      "There are 9 regions for concept names.\n",
      "\n",
      "=============FINISHED INTERPS ROLES==============\n",
      "There are 5 regions for role names.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "domain_embeddings, concept_geointerps, role_geointerps, idx_finder_dict, EMB_DIM, SCALE_FACTOR = create_tbox_embeddings(canmodel, RESTRICT_LANGUAGE, SCALE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding name: Thing\n",
      "In the interpretation of: ['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "Embedding vector: [10. 10. 10. 10. 10. 10. 10. 10. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([0, 1, 2, 3, 4, 5, 6, 7, 8]),)\n",
      "The indices above correspond to these dimensions\" ['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male'] \n",
      "\n",
      "Embedding name: Father\n",
      "In the interpretation of: ['Father']\n",
      "Embedding vector: [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([1]),)\n",
      "The indices above correspond to these dimensions\" ['Father'] \n",
      "\n",
      "Embedding name: And_FFaaeehhrrtt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FMaeehhorrtt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FSaeehoprstu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FSabeghiilnrt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CFadehhilrt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5FQaehrt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FFaaeeehlmrt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FMaaeehlrt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Mother\n",
      "In the interpretation of: ['Mother']\n",
      "Embedding vector: [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([2]),)\n",
      "The indices above correspond to these dimensions\" ['Mother'] \n",
      "\n",
      "Embedding name: And_MMeehhoorrtt\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_MSeehooprstu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_MSbeghiilnort\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CMdehhilort\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5MQehort\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FMaeeehlmort\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_MMaeehlort\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Spouse\n",
      "In the interpretation of: ['Spouse']\n",
      "Embedding vector: [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([3]),)\n",
      "The indices above correspond to these dimensions\" ['Spouse'] \n",
      "\n",
      "Embedding name: And_SSeeooppssuu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_SSbegiilnopsu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CSdehilopsu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5QSeopsu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FSaeeelmopsu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_MSaeelopsu\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Sibling\n",
      "In the interpretation of: ['Sibling']\n",
      "Embedding vector: [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([4]),)\n",
      "The indices above correspond to these dimensions\" ['Sibling'] \n",
      "\n",
      "Embedding name: And_SSbbggiiiillnn\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CSbdghiiilln\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5QSbgiiln\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FSabeegiillmn\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_MSabegiilln\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Child\n",
      "In the interpretation of: ['Child']\n",
      "Embedding vector: [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([5]),)\n",
      "The indices above correspond to these dimensions\" ['Child'] \n",
      "\n",
      "Embedding name: And_CCddhhiill\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5CQdhil\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CFadeehillm\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_CMadehill\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Q5\n",
      "In the interpretation of: ['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "Embedding vector: [ 0. 10. 10. 10. 10. 10. 10. 10. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([1, 2, 3, 4, 5, 6, 7, 8]),)\n",
      "The indices above correspond to these dimensions\" ['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male'] \n",
      "\n",
      "Embedding name: And_55QQ\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5FQaeelm\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_5MQael\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Female\n",
      "In the interpretation of: ['Female']\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([7]),)\n",
      "The indices above correspond to these dimensions\" ['Female'] \n",
      "\n",
      "Embedding name: And_FFaaeeeellmm\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: And_FMaaeeellm\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: Male\n",
      "In the interpretation of: ['Male']\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([8]),)\n",
      "The indices above correspond to these dimensions\" ['Male'] \n",
      "\n",
      "Embedding name: And_MMaaeell\n",
      "In the interpretation of: []\n",
      "Embedding vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "These are the one-hot indices: (array([], dtype=int64),)\n",
      "The indices above correspond to these dimensions\" [] \n",
      "\n",
      "Embedding name: exists_P22.Father\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([10]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Father')] \n",
      "\n",
      "Embedding name: exists_P22.Mother\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([19]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Mother')] \n",
      "\n",
      "Embedding name: exists_P22.Spouse\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([27]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Spouse')] \n",
      "\n",
      "Embedding name: exists_P22.Sibling\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([34]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Sibling')] \n",
      "\n",
      "Embedding name: exists_P22.Child\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([40]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Child')] \n",
      "\n",
      "Embedding name: exists_P22.Q5\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([45]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Q5')] \n",
      "\n",
      "Embedding name: exists_P22.Female\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([49]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Female')] \n",
      "\n",
      "Embedding name: exists_P22.Male\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([52]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Male')] \n",
      "\n",
      "Embedding name: exists_P22.Thing\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([9]),)\n",
      "The indices above correspond to these dimensions\" [('P22', 'Thing')] \n",
      "\n",
      "Embedding name: exists_P25.Father\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([100]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Father')] \n",
      "\n",
      "Embedding name: exists_P25.Mother\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([109]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Mother')] \n",
      "\n",
      "Embedding name: exists_P25.Spouse\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([117]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Spouse')] \n",
      "\n",
      "Embedding name: exists_P25.Sibling\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([124]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Sibling')] \n",
      "\n",
      "Embedding name: exists_P25.Child\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([130]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Child')] \n",
      "\n",
      "Embedding name: exists_P25.Q5\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([135]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Q5')] \n",
      "\n",
      "Embedding name: exists_P25.Female\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([139]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Female')] \n",
      "\n",
      "Embedding name: exists_P25.Male\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([142]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Male')] \n",
      "\n",
      "Embedding name: exists_P25.Thing\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([99]),)\n",
      "The indices above correspond to these dimensions\" [('P25', 'Thing')] \n",
      "\n",
      "Embedding name: exists_P26.Father\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([190]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Father')] \n",
      "\n",
      "Embedding name: exists_P26.Mother\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([199]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Mother')] \n",
      "\n",
      "Embedding name: exists_P26.Spouse\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([207]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Spouse')] \n",
      "\n",
      "Embedding name: exists_P26.Sibling\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([214]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Sibling')] \n",
      "\n",
      "Embedding name: exists_P26.Child\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([220]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Child')] \n",
      "\n",
      "Embedding name: exists_P26.Q5\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([225]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Q5')] \n",
      "\n",
      "Embedding name: exists_P26.Female\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([229]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Female')] \n",
      "\n",
      "Embedding name: exists_P26.Male\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([232]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Male')] \n",
      "\n",
      "Embedding name: exists_P26.Thing\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([189]),)\n",
      "The indices above correspond to these dimensions\" [('P26', 'Thing')] \n",
      "\n",
      "Embedding name: exists_P3373.Father\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([280]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Father')] \n",
      "\n",
      "Embedding name: exists_P3373.Mother\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([289]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Mother')] \n",
      "\n",
      "Embedding name: exists_P3373.Spouse\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([297]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Spouse')] \n",
      "\n",
      "Embedding name: exists_P3373.Sibling\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([304]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Sibling')] \n",
      "\n",
      "Embedding name: exists_P3373.Child\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([310]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Child')] \n",
      "\n",
      "Embedding name: exists_P3373.Q5\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([315]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Q5')] \n",
      "\n",
      "Embedding name: exists_P3373.Female\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([319]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Female')] \n",
      "\n",
      "Embedding name: exists_P3373.Male\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([322]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Male')] \n",
      "\n",
      "Embedding name: exists_P3373.Thing\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([279]),)\n",
      "The indices above correspond to these dimensions\" [('P3373', 'Thing')] \n",
      "\n",
      "Embedding name: exists_P40.Father\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([370]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Father')] \n",
      "\n",
      "Embedding name: exists_P40.Mother\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([379]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Mother')] \n",
      "\n",
      "Embedding name: exists_P40.Spouse\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([387]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Spouse')] \n",
      "\n",
      "Embedding name: exists_P40.Sibling\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([394]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Sibling')] \n",
      "\n",
      "Embedding name: exists_P40.Child\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([400]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Child')] \n",
      "\n",
      "Embedding name: exists_P40.Q5\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([405]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Q5')] \n",
      "\n",
      "Embedding name: exists_P40.Female\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([409]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Female')] \n",
      "\n",
      "Embedding name: exists_P40.Male\n",
      "In the interpretation of: []\n",
      "Embedding vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([412]),)\n",
      "The indices above correspond to these dimensions\" [('P40', 'Male')] \n",
      "\n",
      "Embedding name: exists_P40.Thing\n",
      "In the interpretation of: ['Father', 'Mother']\n",
      "Embedding vector: [ 0. 10. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "These are the one-hot indices: (array([  1,   2, 369]),)\n",
      "The indices above correspond to these dimensions\" ['Father', 'Mother', ('P40', 'Thing')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for embedding in domain_embeddings:\n",
    "    print(f'Embedding name: {embedding.name}')\n",
    "    print(f'In the interpretation of: {embedding.in_interpretation_of}')\n",
    "    print(f'Embedding vector: {embedding.embedding_vector}')\n",
    "    print(f'These are the one-hot indices: {np.where(embedding.embedding_vector != 0)}')\n",
    "    print(f'The indices above correspond to these dimensions\" {[idx_finder_dict[int(idx)] for idx in np.where(embedding.embedding_vector != 0)[0]]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering role: P22\n",
      "There are 9 elements in the vertex set for P22\n",
      "First vector one_hot_idx: [10]\n",
      "First vector correspondence indices: [('P22', 'Father')]\n",
      "Second vector one_hot_idx: [1]\n",
      "Second vector correspondence indices['Father']\n",
      "\n",
      "First vector one_hot_idx: [19]\n",
      "First vector correspondence indices: [('P22', 'Mother')]\n",
      "Second vector one_hot_idx: [2]\n",
      "Second vector correspondence indices['Mother']\n",
      "\n",
      "First vector one_hot_idx: [27]\n",
      "First vector correspondence indices: [('P22', 'Spouse')]\n",
      "Second vector one_hot_idx: [3]\n",
      "Second vector correspondence indices['Spouse']\n",
      "\n",
      "First vector one_hot_idx: [34]\n",
      "First vector correspondence indices: [('P22', 'Sibling')]\n",
      "Second vector one_hot_idx: [4]\n",
      "Second vector correspondence indices['Sibling']\n",
      "\n",
      "First vector one_hot_idx: [40]\n",
      "First vector correspondence indices: [('P22', 'Child')]\n",
      "Second vector one_hot_idx: [5]\n",
      "Second vector correspondence indices['Child']\n",
      "\n",
      "First vector one_hot_idx: [45]\n",
      "First vector correspondence indices: [('P22', 'Q5')]\n",
      "Second vector one_hot_idx: [1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "First vector one_hot_idx: [49]\n",
      "First vector correspondence indices: [('P22', 'Female')]\n",
      "Second vector one_hot_idx: [7]\n",
      "Second vector correspondence indices['Female']\n",
      "\n",
      "First vector one_hot_idx: [52]\n",
      "First vector correspondence indices: [('P22', 'Male')]\n",
      "Second vector one_hot_idx: [8]\n",
      "Second vector correspondence indices['Male']\n",
      "\n",
      "First vector one_hot_idx: [9]\n",
      "First vector correspondence indices: [('P22', 'Thing')]\n",
      "Second vector one_hot_idx: [0 1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "======================NEXT ROLE======================\n",
      "Considering role: P25\n",
      "There are 9 elements in the vertex set for P25\n",
      "First vector one_hot_idx: [100]\n",
      "First vector correspondence indices: [('P25', 'Father')]\n",
      "Second vector one_hot_idx: [1]\n",
      "Second vector correspondence indices['Father']\n",
      "\n",
      "First vector one_hot_idx: [109]\n",
      "First vector correspondence indices: [('P25', 'Mother')]\n",
      "Second vector one_hot_idx: [2]\n",
      "Second vector correspondence indices['Mother']\n",
      "\n",
      "First vector one_hot_idx: [117]\n",
      "First vector correspondence indices: [('P25', 'Spouse')]\n",
      "Second vector one_hot_idx: [3]\n",
      "Second vector correspondence indices['Spouse']\n",
      "\n",
      "First vector one_hot_idx: [124]\n",
      "First vector correspondence indices: [('P25', 'Sibling')]\n",
      "Second vector one_hot_idx: [4]\n",
      "Second vector correspondence indices['Sibling']\n",
      "\n",
      "First vector one_hot_idx: [130]\n",
      "First vector correspondence indices: [('P25', 'Child')]\n",
      "Second vector one_hot_idx: [5]\n",
      "Second vector correspondence indices['Child']\n",
      "\n",
      "First vector one_hot_idx: [135]\n",
      "First vector correspondence indices: [('P25', 'Q5')]\n",
      "Second vector one_hot_idx: [1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "First vector one_hot_idx: [139]\n",
      "First vector correspondence indices: [('P25', 'Female')]\n",
      "Second vector one_hot_idx: [7]\n",
      "Second vector correspondence indices['Female']\n",
      "\n",
      "First vector one_hot_idx: [142]\n",
      "First vector correspondence indices: [('P25', 'Male')]\n",
      "Second vector one_hot_idx: [8]\n",
      "Second vector correspondence indices['Male']\n",
      "\n",
      "First vector one_hot_idx: [99]\n",
      "First vector correspondence indices: [('P25', 'Thing')]\n",
      "Second vector one_hot_idx: [0 1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "======================NEXT ROLE======================\n",
      "Considering role: P26\n",
      "There are 9 elements in the vertex set for P26\n",
      "First vector one_hot_idx: [190]\n",
      "First vector correspondence indices: [('P26', 'Father')]\n",
      "Second vector one_hot_idx: [1]\n",
      "Second vector correspondence indices['Father']\n",
      "\n",
      "First vector one_hot_idx: [199]\n",
      "First vector correspondence indices: [('P26', 'Mother')]\n",
      "Second vector one_hot_idx: [2]\n",
      "Second vector correspondence indices['Mother']\n",
      "\n",
      "First vector one_hot_idx: [207]\n",
      "First vector correspondence indices: [('P26', 'Spouse')]\n",
      "Second vector one_hot_idx: [3]\n",
      "Second vector correspondence indices['Spouse']\n",
      "\n",
      "First vector one_hot_idx: [214]\n",
      "First vector correspondence indices: [('P26', 'Sibling')]\n",
      "Second vector one_hot_idx: [4]\n",
      "Second vector correspondence indices['Sibling']\n",
      "\n",
      "First vector one_hot_idx: [220]\n",
      "First vector correspondence indices: [('P26', 'Child')]\n",
      "Second vector one_hot_idx: [5]\n",
      "Second vector correspondence indices['Child']\n",
      "\n",
      "First vector one_hot_idx: [225]\n",
      "First vector correspondence indices: [('P26', 'Q5')]\n",
      "Second vector one_hot_idx: [1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "First vector one_hot_idx: [229]\n",
      "First vector correspondence indices: [('P26', 'Female')]\n",
      "Second vector one_hot_idx: [7]\n",
      "Second vector correspondence indices['Female']\n",
      "\n",
      "First vector one_hot_idx: [232]\n",
      "First vector correspondence indices: [('P26', 'Male')]\n",
      "Second vector one_hot_idx: [8]\n",
      "Second vector correspondence indices['Male']\n",
      "\n",
      "First vector one_hot_idx: [189]\n",
      "First vector correspondence indices: [('P26', 'Thing')]\n",
      "Second vector one_hot_idx: [0 1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "======================NEXT ROLE======================\n",
      "Considering role: P3373\n",
      "There are 9 elements in the vertex set for P3373\n",
      "First vector one_hot_idx: [280]\n",
      "First vector correspondence indices: [('P3373', 'Father')]\n",
      "Second vector one_hot_idx: [1]\n",
      "Second vector correspondence indices['Father']\n",
      "\n",
      "First vector one_hot_idx: [289]\n",
      "First vector correspondence indices: [('P3373', 'Mother')]\n",
      "Second vector one_hot_idx: [2]\n",
      "Second vector correspondence indices['Mother']\n",
      "\n",
      "First vector one_hot_idx: [297]\n",
      "First vector correspondence indices: [('P3373', 'Spouse')]\n",
      "Second vector one_hot_idx: [3]\n",
      "Second vector correspondence indices['Spouse']\n",
      "\n",
      "First vector one_hot_idx: [304]\n",
      "First vector correspondence indices: [('P3373', 'Sibling')]\n",
      "Second vector one_hot_idx: [4]\n",
      "Second vector correspondence indices['Sibling']\n",
      "\n",
      "First vector one_hot_idx: [310]\n",
      "First vector correspondence indices: [('P3373', 'Child')]\n",
      "Second vector one_hot_idx: [5]\n",
      "Second vector correspondence indices['Child']\n",
      "\n",
      "First vector one_hot_idx: [315]\n",
      "First vector correspondence indices: [('P3373', 'Q5')]\n",
      "Second vector one_hot_idx: [1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "First vector one_hot_idx: [319]\n",
      "First vector correspondence indices: [('P3373', 'Female')]\n",
      "Second vector one_hot_idx: [7]\n",
      "Second vector correspondence indices['Female']\n",
      "\n",
      "First vector one_hot_idx: [322]\n",
      "First vector correspondence indices: [('P3373', 'Male')]\n",
      "Second vector one_hot_idx: [8]\n",
      "Second vector correspondence indices['Male']\n",
      "\n",
      "First vector one_hot_idx: [279]\n",
      "First vector correspondence indices: [('P3373', 'Thing')]\n",
      "Second vector one_hot_idx: [0 1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "======================NEXT ROLE======================\n",
      "Considering role: P40\n",
      "There are 9 elements in the vertex set for P40\n",
      "First vector one_hot_idx: [370]\n",
      "First vector correspondence indices: [('P40', 'Father')]\n",
      "Second vector one_hot_idx: [1]\n",
      "Second vector correspondence indices['Father']\n",
      "\n",
      "First vector one_hot_idx: [379]\n",
      "First vector correspondence indices: [('P40', 'Mother')]\n",
      "Second vector one_hot_idx: [2]\n",
      "Second vector correspondence indices['Mother']\n",
      "\n",
      "First vector one_hot_idx: [387]\n",
      "First vector correspondence indices: [('P40', 'Spouse')]\n",
      "Second vector one_hot_idx: [3]\n",
      "Second vector correspondence indices['Spouse']\n",
      "\n",
      "First vector one_hot_idx: [394]\n",
      "First vector correspondence indices: [('P40', 'Sibling')]\n",
      "Second vector one_hot_idx: [4]\n",
      "Second vector correspondence indices['Sibling']\n",
      "\n",
      "First vector one_hot_idx: [400]\n",
      "First vector correspondence indices: [('P40', 'Child')]\n",
      "Second vector one_hot_idx: [5]\n",
      "Second vector correspondence indices['Child']\n",
      "\n",
      "First vector one_hot_idx: [405]\n",
      "First vector correspondence indices: [('P40', 'Q5')]\n",
      "Second vector one_hot_idx: [1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "First vector one_hot_idx: [409]\n",
      "First vector correspondence indices: [('P40', 'Female')]\n",
      "Second vector one_hot_idx: [7]\n",
      "Second vector correspondence indices['Female']\n",
      "\n",
      "First vector one_hot_idx: [412]\n",
      "First vector correspondence indices: [('P40', 'Male')]\n",
      "Second vector one_hot_idx: [8]\n",
      "Second vector correspondence indices['Male']\n",
      "\n",
      "First vector one_hot_idx: [  1   2 369]\n",
      "First vector correspondence indices: ['Father', 'Mother', ('P40', 'Thing')]\n",
      "Second vector one_hot_idx: [0 1 2 3 4 5 6 7 8]\n",
      "Second vector correspondence indices['Thing', 'Father', 'Mother', 'Spouse', 'Sibling', 'Child', 'Q5', 'Female', 'Male']\n",
      "\n",
      "======================NEXT ROLE======================\n"
     ]
    }
   ],
   "source": [
    "for role_name, geointerp in GeometricInterpretation.role_geointerps_dict.items():\n",
    "    print(f'Considering role: {role_name}')\n",
    "    print(f'There are {len(geointerp.vertices)} elements in the vertex set for {role_name}')\n",
    "    for vertex in geointerp.vertices:\n",
    "        one_hot_idx_one = np.where(vertex[:459] != 0)[0]\n",
    "        one_hot_idx_two = np.where(vertex[459:] != 0)[0]\n",
    "        print(f'First vector one_hot_idx: {one_hot_idx_one}')\n",
    "        first_vector_correspondence = [idx_finder_dict[int(idx)] for idx in one_hot_idx_one]\n",
    "        print(f'First vector correspondence indices: {first_vector_correspondence}')\n",
    "        print(f'Second vector one_hot_idx: {one_hot_idx_two}')\n",
    "        second_vector_correspondence = [idx_finder_dict[int(idx)] for idx in one_hot_idx_two]\n",
    "        print(f'Second vector correspondence indices{second_vector_correspondence}\\n')\n",
    "    print('======================NEXT ROLE======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restriction_vertices(restriction_concept, concept_geointerps_dict, role_geointerps_dict, index_finder_dict, CanonicalModel: CanonicalModel, EntityEmbedding: EntityEmbedding):\n",
    "    \n",
    "    concept_name = restriction_concept.value\n",
    "    role_name = restriction_concept.property\n",
    "\n",
    "    concept_name_str = concept_name.name\n",
    "    role_name_str = role_name.name\n",
    "\n",
    "    vertices = []\n",
    "\n",
    "    for element in list(CanonicalModel.role_canonical_interpretation.keys()):\n",
    "        if role_name_str in element:\n",
    "            role_interpretation_set = CanonicalModel.role_canonical_interpretation[role_name_str]\n",
    "\n",
    "            for pair in role_interpretation_set:\n",
    "                element_1 = pair[0]\n",
    "                element_2 = pair[1]\n",
    "\n",
    "                if element_2 in CanonicalModel.concept_canonical_interpretation[concept_name_str]:\n",
    "                    vertices.append(EntityEmbedding.entity_entityvector_dict[element_1])\n",
    "    \n",
    "    return np.array(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_vertices(restriction_concept, concept_geointerps_dict, role_geointerps_dict, index_finder_dict, CanonicalModel: CanonicalModel, EntityEmbedding: EntityEmbedding):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for creating the pre-split dataset containing facts from the ontology.\n",
    "Distinguishes between concept assertions and role assertions.\n",
    "\n",
    "\n",
    "    Args: ontology_dir (str): the directory from the ontology\n",
    "          concept_geointerps_dict (dict): the geometrical interpretations for concepts generated by create_tbox_embeddings()\n",
    "          role_geointerps_dict (dict): the geometrical interpretations for roles generated by create_tbox_embeddings()\n",
    "\n",
    "    Returns:\n",
    "          X_concepts (np.array): A dataframe with columns 'Concept', 'Entity', 'y_true' (equivalent to concept.centroid())\n",
    "          X_roles (np.array): A dataframe with columns 'SubjectEntity', 'Role', 'ObjectEntity', 'y_true' (equivalent to role.centroid())\n",
    "          y_concepts (np.array):\n",
    "          y_roles (np.array):\n",
    "          vocabulary_dict (dict): A vocabulary with key (int): value (str) for entities in the domain.\n",
    "'''\n",
    "\n",
    "def get_abox_dataset(ontology_dir: str,\n",
    "                     concept_geointerps_dict: dict, role_geointerps_dict: dict,\n",
    "                     concept_to_idx: dict, role_to_idx: dict,\n",
    "                     index_finder_dict: dict, emb_dim = int,\n",
    "                     CanonicalModel = CanonicalModel, EntityEmbedding=EntityEmbedding):\n",
    "    \n",
    "    ontology = get_ontology(ontology_dir)\n",
    "    ontology = ontology.load()\n",
    "    \n",
    "    X_concepts = []\n",
    "    X_roles = []\n",
    "    y_concepts = []\n",
    "    y_roles = []\n",
    "\n",
    "    entities = [entity.name for entity in list(ontology.individuals())]\n",
    "    \n",
    "    concept_to_idx_vocab = concept_to_idx\n",
    "    idx_to_concept_vocab = {value: key for key, value in concept_to_idx_vocab.items()}\n",
    "\n",
    "    role_to_idx_vocab = role_to_idx\n",
    "    idx_to_role_vocab = {value: key for key, value in role_to_idx_vocab.items()}\n",
    "    \n",
    "    entity_to_idx_vocab = {value: index for index, value in enumerate(entities)}\n",
    "    idx_to_entity_vocab = {value: key for key, value in entity_to_idx_vocab.items()}\n",
    "\n",
    "    for individual in list(ontology.individuals()):\n",
    "\n",
    "        all_facts = individual.INDIRECT_is_a\n",
    "\n",
    "        for concept in all_facts:\n",
    "            # Handles concepts of the type A\n",
    "            if type(concept) == ThingClass:\n",
    "                concept = concept_geointerps_dict[concept.name]\n",
    "                fact = np.array([concept_to_idx_vocab[concept.name], entity_to_idx_vocab[individual.name]])\n",
    "                y_label = np.array(concept.centroid)\n",
    "                X_concepts.append(fact)\n",
    "                y_concepts.append(y_label)\n",
    "                \n",
    "            # Handles concepts of the type A \\and B\n",
    "            elif type(concept) == And:\n",
    "                concept1 = concept_geointerps_dict[concept.Classes[0]]\n",
    "                concept2 = concept_geointerps_dict[concept.Classes[1]]\n",
    "                intersection_name = 'And_' + ''.join(sorted(concept1.name + concept2.name))\n",
    "\n",
    "                if concept_to_idx_vocab.get(intersection_name) is not None:\n",
    "                    fact = np.array([concept_to_idx_vocab[intersection_name], entity_to_idx_vocab[individual.name]])\n",
    "                    y_label = np.array((concept1.centroid + concept2.centroid)/2) # The golden label for an intersection is just the average of the centroid of the two regions\n",
    "                    X_concepts.append(fact)\n",
    "                    y_concepts.append(y_label)\n",
    "\n",
    "                else:\n",
    "                    concept_to_idx_vocab[intersection_name] = len(concept_to_idx_vocab)\n",
    "                    idx_to_concept_vocab[len(concept_to_idx_vocab)] = intersection_name\n",
    "                    fact = np.array([concept_to_idx_vocab[intersection_name], entity_to_idx_vocab[individual.name]])\n",
    "                    y_label = np.array((concept1.centroid + concept2.centroid)/2) # The golden label for an intersection is just the average of the centroid of the two regions\n",
    "                    X_concepts.append(fact)\n",
    "                    y_concepts.append(y_label)\n",
    "            \n",
    "            # Handles concepts of the type \\exists r.B\n",
    "            elif type(concept) == Restriction:\n",
    "                concept_name = concept.value\n",
    "                role_name = concept.property\n",
    "                restriction_name = 'exists_' + role_name.name + '.' + concept_name.name\n",
    "\n",
    "                if concept_to_idx_vocab.get(restriction_name) is not None:\n",
    "                \n",
    "                    fact = np.array([concept_to_idx_vocab[restriction_name], entity_to_idx_vocab[individual.name]])\n",
    "                    y_label = np.array(GeometricInterpretation.concept_geointerps_dict[restriction_name].centroid)\n",
    "                    X_concepts.append(fact)\n",
    "                    y_concepts.append(y_label)\n",
    "\n",
    "                else:\n",
    "                    concept_to_idx_vocab[restriction_name] = len(concept_to_idx_vocab)\n",
    "                    idx_to_concept_vocab[len(concept_to_idx_vocab)-1] = restriction_name\n",
    "                    restriction_concept = GeometricInterpretation(restriction_name, EMB_DIM) # Initializes a Geometric Interpretation type object\n",
    "                    restriction_concept.vertices = get_restriction_vertices(concept, concept_geointerps_dict,\n",
    "                                                                            role_geointerps_dict, index_finder_dict, CanonicalModel, EntityEmbedding)\n",
    "                    \n",
    "                    GeometricInterpretation.concept_geointerps_dict[restriction_name] = restriction_concept\n",
    "                    restriction_concept.centroid = restriction_concept.get_centroid_naive()\n",
    "                    fact = np.array([concept_to_idx_vocab[restriction_concept.name], entity_to_idx_vocab[individual.name]])\n",
    "                    y_label = restriction_concept.centroid\n",
    "                    X_concepts.append(fact)\n",
    "                    y_concepts.append(y_label)\n",
    "\n",
    "        relevant_roles = individual.get_properties()\n",
    "        individual_name = individual.name\n",
    "\n",
    "        for role in relevant_roles:\n",
    "\n",
    "            role_geo = role_geointerps_dict[role.name]\n",
    "            subject_list = role[individual] # This syntax is from the owlready2 library\n",
    "\n",
    "            for subject in subject_list:\n",
    "                fact = np.array([entity_to_idx_vocab[individual.name], role_to_idx_vocab[role.name], entity_to_idx_vocab[subject.name]])\n",
    "\n",
    "                X_roles.append(fact)\n",
    "                y_label = y_roles.append(np.array(role_geo.centroid))\n",
    "\n",
    "    return np.array(X_concepts), np.array(X_roles), np.array(y_concepts), np.array(y_roles), entity_to_idx_vocab, idx_to_entity_vocab, concept_to_idx_vocab, idx_to_concept_vocab, role_to_idx_vocab, idx_to_role_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concepts, X_roles, y_concepts, y_roles, entity_to_idx_vocab, idx_to_entity_vocab, concept_to_idx_vocab, idx_to_concept_vocab, role_to_idx_vocab, idx_to_role_vocab = get_abox_dataset(dir,\n",
    "                                                                                                                                                                                        GeometricInterpretation.concept_geointerps_dict,\n",
    "                                                                                                                                                                                        GeometricInterpretation.role_geointerps_dict,\n",
    "                                                                                                                                                                                        EntityEmbedding.concept_names_idx_dict,\n",
    "                                                                                                                                                                                        EntityEmbedding.role_names_idx_dict,\n",
    "                                                                                                                                                                                        idx_finder_dict,\n",
    "                                                                                                                                                                                        EMB_DIM,\n",
    "                                                                                                                                                                                        CanonicalModel, EntityEmbedding\n",
    "                                                                                                                                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.X = torch.tensor(data, dtype=torch.long)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].long(), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE_PROPORTION = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(200)\n",
    "ConceptDataset = OntologyDataset(X_concepts, y_concepts)\n",
    "\n",
    "dataset_size = len(ConceptDataset)\n",
    "train_size = int(TRAIN_SIZE_PROPORTION * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "trainConceptDataset, testConceptDataset = torch.utils.data.random_split(ConceptDataset, [train_size, test_size])\n",
    "RoleDataset = OntologyDataset(X_roles, y_roles)\n",
    "\n",
    "dataset_size = len(RoleDataset)\n",
    "train_size = int(TRAIN_SIZE_PROPORTION * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "trainRoleDataset, testRoleDataset = torch.utils.data.random_split(RoleDataset, [train_size, test_size])\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_ConceptDataLoader = DataLoader(trainConceptDataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_ConceptDataLoader = DataLoader(testConceptDataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_RoleDataLoader = DataLoader(trainRoleDataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "test_RoleDataLoader = DataLoader(testRoleDataset, batch_size = BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaithEL(nn.Module):\n",
    "    def __init__(self, emb_dim, phi, radius,\n",
    "                 individual_vocabulary,\n",
    "                 concept_vocabulary,\n",
    "                 role_vocabulary,\n",
    "                 init_individual_param_to_centroid = False,\n",
    "                 init_concept_param_to_centroid = False,\n",
    "                 init_role_param_to_centroid = False):\n",
    "        \n",
    "        super(FaithEL, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.phi = phi\n",
    "        self.radius = radius\n",
    "\n",
    "        self.individual_embedding_dict = nn.Embedding(len(individual_vocabulary),\n",
    "                                                      emb_dim\n",
    "                                                      )\n",
    "        \n",
    "        if init_individual_param_to_centroid == True:\n",
    "            with torch.no_grad():\n",
    "                value = SCALE_FACTOR/2\n",
    "                std_dev = 0.3\n",
    "                self.individual_embedding_dict.weight.data.normal_(mean=value, std=std_dev)\n",
    "        \n",
    "        self.concept_embedding_dict = nn.Embedding(len(concept_vocabulary),\n",
    "                                                   emb_dim\n",
    "                                                   )\n",
    "        \n",
    "        # Initializes the moving parameter for concepts at the concept's respective centroid\n",
    "        if init_concept_param_to_centroid == True:\n",
    "            with torch.no_grad():\n",
    "                for concept_name, concept_idx in concept_vocabulary.items():\n",
    "                    self.concept_embedding_dict.weight[concept_idx] = torch.tensor(GeometricInterpretation.concept_geointerps_dict[concept_name].centroid)\n",
    "\n",
    "        self.role_embedding_dict = nn.Embedding(len(role_vocabulary),\n",
    "                                                emb_dim * 2\n",
    "                                                )\n",
    "        \n",
    "        # Initializes the moving parameter for roles at the role's respective centroid\n",
    "        if init_role_param_to_centroid == True:\n",
    "            with torch.no_grad():\n",
    "                for role_name, role_idx in role_vocabulary.items():\n",
    "                    self.role_embedding_dict.weight[role_idx] = torch.tensor(GeometricInterpretation.role_geointerps_dict[role_name].centroid)\n",
    "    \n",
    "    def forward(self, data):\n",
    "    \n",
    "        # Concept assertions are of the form ['Concept', 'Entity']\n",
    "        # Role assertions are of the form ['SubjectEntity', 'Role', 'ObjectEntity']\n",
    "        \n",
    "        subj_entity_idx = 1 if len(data[0]) == 2 else 0 # Checks whether the model has received a C assert or R assert\n",
    "\n",
    "        if subj_entity_idx == 1:\n",
    "\n",
    "            #print(f'This is the data: {data}')\n",
    "            #print(f'This is the data shape: {data.shape}')\n",
    "\n",
    "            concept_idx = 0\n",
    "            \n",
    "            concept = data[:, concept_idx]\n",
    "            #print(f'concept shape: {concept.shape}')\n",
    "            subj_entity = data[:, subj_entity_idx]\n",
    "            #print(f'subj_entity shape: {subj_entity.shape}')\n",
    "            neg_object_entity = torch.randint(0, self.individual_embedding_dict.weight.shape[0], (subj_entity.shape))\n",
    "            #print(f'neg_object_entity shape: {neg_object_entity.shape}')\n",
    "\n",
    "            #print(f'Concept Subject entity: {subj_entity}')\n",
    "            #print(f'Concept Negative sampled entities: {neg_object_entity}')\n",
    "\n",
    "            out1 = self.concept_embedding_dict(concept) # Outputs the moving parameter for the concept\n",
    "            out2 = self.individual_embedding_dict(subj_entity) # Outputs the embedding for the individual\n",
    "            out3 = self.individual_embedding_dict(neg_object_entity)\n",
    "            \n",
    "            return out1, out2, out3\n",
    "\n",
    "        elif subj_entity_idx == 0:\n",
    "        \n",
    "            role_idx = 1\n",
    "            obj_entity_idx = 2\n",
    "            \n",
    "            role = data[:, role_idx]\n",
    "            subject_entity = data[:, subj_entity_idx]\n",
    "            object_entity = data[:, obj_entity_idx]\n",
    "        \n",
    "            #subject_entity = self.individual_embedding_dict(data[:, subj_entity_idx])\n",
    "            #object_entity = self.individual_embedding_dict(data[:, obj_entity_idx])\n",
    "            #role = self.role_embedding_dict(data[:, role_idx])\n",
    "            neg_object_entity = torch.randint(0, self.individual_embedding_dict.weight.shape[0], (subject_entity.shape))\n",
    "\n",
    "            #print(f'Role Subject entity: {subject_entity}')\n",
    "            #print(f'Role Negative sampled entities: {neg_object_entity}')\n",
    "\n",
    "            out1 = self.role_embedding_dict(role) # Role parameter embedding\n",
    "            out2 = torch.cat((self.individual_embedding_dict(subject_entity), self.individual_embedding_dict(object_entity)), 1)\n",
    "            #print(f'Out2: {out2}')\n",
    "            #print(f'Out2 shape: {out2.shape}')\n",
    "            out3 = torch.cat((self.individual_embedding_dict(subject_entity), self.individual_embedding_dict(neg_object_entity)), 1)\n",
    "            #print(f'Out3: {out3}')\n",
    "            #print(f'Out3 shape: {out3.shape}')\n",
    "\n",
    "            #out2 = torch.cat((subject_entity, object_entity), 1) # Concatenation of subject and object\n",
    "            #out3 = torch.cat((subject_entity, neg_object_entity), 1) # Concatenation of subject and randomly sampled negative object entity\n",
    "            \n",
    "            return out1, out2, out3\n",
    "        \n",
    "    def concept_parameter_constraint(self):\n",
    "        with torch.no_grad():\n",
    "            for idx, weight in enumerate(self.concept_embedding_dict.weight):\n",
    "                centroid = torch.tensor(GeometricInterpretation.concept_geointerps_dict[list(GeometricInterpretation.concept_geointerps_dict.keys())[idx]].centroid)\n",
    "                distance = torch.dist(weight, centroid, p=2)\n",
    "                if distance > self.radius:\n",
    "                    self.concept_embedding_dict.weight[idx] = centroid + self.radius * (weight - centroid) / distance\n",
    "\n",
    "    def role_parameter_constraint(self):\n",
    "        with torch.no_grad():\n",
    "            for idx, weight in enumerate(self.role_embedding_dict.weight):\n",
    "                centroid = torch.tensor(GeometricInterpretation.role_geointerps_dict[list(GeometricInterpretation.role_geointerps_dict.keys())[idx]].centroid)\n",
    "                distance = torch.dist(weight, centroid, p=2)\n",
    "                if distance > self.radius:\n",
    "                    self.role_embedding_dict.weight[idx] = centroid + self.radius * (weight - centroid) / distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_dists(model, dictionary_concept_to_idx, role = False):\n",
    "\n",
    "    dist_dict = {}\n",
    "\n",
    "    for predicate, idx in dictionary_concept_to_idx.items():\n",
    "        with torch.no_grad():\n",
    "            if role == False:\n",
    "                dist = torch.dist(torch.tensor(GeometricInterpretation.concept_geointerps_dict[predicate].centroid), model.concept_embedding_dict.weight[idx])\n",
    "                dist_dict[predicate] = dist\n",
    "            else:\n",
    "                dist = torch.dist(torch.tensor(GeometricInterpretation.role_geointerps_dict[predicate].centroid), model.concept_embedding_dict.weight[idx])\n",
    "                dist_dict[predicate] = dist\n",
    "\n",
    "    return dist_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, concept_dataloader, role_dataloader, loss_fn, optimizer, alternate_training = False, neg_sampling = True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(concept_dataloader)\n",
    "\n",
    "    if alternate_training == False and neg_sampling == True:\n",
    "\n",
    "        for i, data in enumerate(role_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # outputs1 = Role Parameter, outputs2 = Entity concat parameter, outputs3 = neg_candidate\n",
    "            loss = (loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)) + -torch.dist(outputs2, outputs3, p=2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.role_parameter_constraint()\n",
    "\n",
    "        for i, data in enumerate(concept_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # Outputs 1 = Concept Parameter, Outputs 2 = Entity Parameter\n",
    "            loss = (loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)) + -torch.dist(outputs2, outputs3, p=2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.concept_parameter_constraint()\n",
    "    \n",
    "    elif alternate_training == False:\n",
    "\n",
    "        for i, data in enumerate(role_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # Outputs 1 = Role Parameter, Outputs 2 = Entity concat parameter\n",
    "            loss = loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.role_parameter_constraint()\n",
    "\n",
    "        for i, data in enumerate(concept_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # Outputs 1 = Concept Parameter, Outputs 2 = Entity Parameter\n",
    "            loss = loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.concept_parameter_constraint()\n",
    "\n",
    "    elif alternate_training == True:\n",
    "\n",
    "        for i, data in enumerate(role_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # Outputs 1 = Role Parameter, Outputs 2 = Entity concat parameter\n",
    "            cosine_target = torch.ones(outputs1.shape[0])\n",
    "            loss = loss_fn(outputs2, labels, cosine_target) + loss_fn(outputs1, outputs2, cosine_target) + model.phi * loss_fn(outputs1, labels, cosine_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.role_parameter_constraint()\n",
    "\n",
    "        for i, data in enumerate(concept_dataloader):\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs1, outputs2, outputs3 = model(inputs) # Outputs 1 = Concept Parameter, Outputs 2 = Entity Parameter\n",
    "            cosine_target = torch.ones(outputs1.shape[0])\n",
    "            loss = loss_fn(outputs2, labels, cosine_target) + loss_fn(outputs1, outputs2, cosine_target) + model.phi * loss_fn(outputs1, labels, cosine_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            model.concept_parameter_constraint()\n",
    "\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, concept_dataloader, role_dataloader, loss_fn, alternate_training = False):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(concept_dataloader)\n",
    "\n",
    "    if alternate_training == False:\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, data in enumerate(role_dataloader):\n",
    "                inputs, labels = data\n",
    "                outputs1, outputs2, outputs3 = model(inputs)\n",
    "                loss = loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            for i, data in enumerate(concept_dataloader):\n",
    "                inputs, labels = data\n",
    "                outputs1, outputs2, outputs3 = model(inputs)\n",
    "                loss = loss_fn(outputs2, labels) + loss_fn(outputs1, outputs2) + model.phi * loss_fn(outputs1, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, data in enumerate(role_dataloader):\n",
    "                inputs, labels = data\n",
    "                outputs1, outputs2, outputs3 = model(inputs)\n",
    "                cosine_target = torch.tensor(1).unsqueeze(0)\n",
    "                loss = loss_fn(outputs2, labels, cosine_target) + loss_fn(outputs1, outputs2, cosine_target) + model.phi * loss_fn(outputs1, labels, cosine_target)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            for i, data in enumerate(concept_dataloader):\n",
    "                inputs, labels = data\n",
    "                outputs1, outputs2, outputs3 = model(inputs)\n",
    "                cosine_target = torch.tensor(1).unsqueeze(0)\n",
    "                loss = loss_fn(outputs2, labels, cosine_target) + loss_fn(outputs1, outputs2, cosine_target) + model.phi * loss_fn(outputs1, labels, cosine_target)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hits_at_k_concept_assertions(model,\n",
    "                  test_concept_assertions: Dataset, test_role_assertions: Dataset,\n",
    "                  entity_to_idx_vocab: dict, idx_to_entity_vocab: dict,\n",
    "                  idx_to_concept_vocab: dict, idx_to_role_vocab: dict,\n",
    "                  centroid_score: False, alt_training: False\n",
    "                  ):\n",
    "    \n",
    "    top1 = 0\n",
    "    top3 = 0\n",
    "    top10 = 0\n",
    "    top100 = 0\n",
    "    top_all = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    hits = []\n",
    "\n",
    "    relevant_concept_idx = []\n",
    "\n",
    "    # Gathers only concepts appearing in the test set (it is not guaranteed that if a concept appears in the dataset, then it appears here)\n",
    "\n",
    "    for assertion in test_concept_assertions:\n",
    "        inputs, _ = assertion\n",
    "        if inputs[0] not in relevant_concept_idx:\n",
    "            relevant_concept_idx.append(inputs[0])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # print(f'Relevant concept idx: {relevant_concept_idx}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for concept_idx in relevant_concept_idx:\n",
    "\n",
    "            assertion_scores = []\n",
    "\n",
    "            for _, entity_idx in entity_to_idx_vocab.items():\n",
    "                eval_sample = torch.tensor([concept_idx, entity_idx]).unsqueeze(0)\n",
    "                outputs1, outputs2, outputs3 = model(eval_sample) # out1 = Concept parameter, out2 = Individual parameter\n",
    "\n",
    "                if centroid_score == False:\n",
    "                    assertion_score = torch.dist(outputs1, outputs2, p=2) # Distance from the individual embedding from the concept parameter embedding\n",
    "                elif alt_training == True:\n",
    "                    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "                    assertion_score = cos(outputs1, outputs2,) + cos(outputs2, torch.tensor(GeometricInterpretation.concept_geointerps_dict[idx_to_concept_vocab[int(concept_idx)]].centroid))\n",
    "                elif alt_training == False and centroid_score == True:\n",
    "                    assertion_score = torch.dist(outputs1, outputs2, p=2) + torch.dist(outputs2, torch.tensor(GeometricInterpretation.concept_geointerps_dict[idx_to_concept_vocab[int(concept_idx)]].centroid)) \n",
    "                    # Distance from the individual embedding from concept param embedding plus distance from the ind emb to the centroid of the geointerp of the concept\n",
    "\n",
    "                assertion_scores.append((torch.tensor([concept_idx, entity_idx]), assertion_score.item()))\n",
    "            \n",
    "            sorted_scores = sorted(assertion_scores, key=lambda x: x[1])\n",
    "\n",
    "            #print(f'Current query concept: {concept_idx}')\n",
    "            #print(f'Centroid_score = {centroid_score}')\n",
    "            #print(f'Assertion scores: {assertion_scores}')\n",
    "            #print(f'Sorted scores: {sorted_scores}\\n')\n",
    "\n",
    "            k_list = [1, 3, 10, 100, len(assertion_scores)]\n",
    "            hit_k_values = []\n",
    "\n",
    "            true_samples = [inputs for inputs, _ in test_concept_assertions if inputs[0] == concept_idx] # This is problematic when dealing with big datasets\n",
    "\n",
    "            #print(f'True samples in evaluation dset: {true_samples}')\n",
    "\n",
    "            for k in k_list:\n",
    "                hit_k = any(torch.equal(scored_sample[0], true_sample) for true_sample in true_samples for scored_sample in sorted_scores[:k])\n",
    "                hit_k_values.append(hit_k)\n",
    "                #print(f'Top{k}hits: {hit_k}')\n",
    "            \n",
    "            hits.append(hit_k_values)\n",
    "\n",
    "            top1 += int(hit_k_values[0])\n",
    "            top3 += int(hit_k_values[1])\n",
    "            top10 += int(hit_k_values[2])\n",
    "            top100 += int(hit_k_values[3])\n",
    "            top_all += int(hit_k_values[4])\n",
    "\n",
    "    hits_at_k = [round(sum(hit_values) / len(hit_values), 3) for hit_values in zip(*hits)]  # Calculate hits_at_k for each k\n",
    "\n",
    "    # return hits_at_k, [top1, top3, top10, top100, top_all]\n",
    "    return hits_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hits_at_k_role_assertions(model,\n",
    "                  test_concept_assertions: Dataset, test_role_assertions: Dataset,\n",
    "                  entity_to_idx_vocab: dict, idx_to_entity_vocab: dict,\n",
    "                  idx_to_concept_vocab: dict, idx_to_role_vocab: dict,\n",
    "                  centroid_score = False, alt_training = False\n",
    "                  ):\n",
    "    \n",
    "    top1 = 0\n",
    "    top3 = 0\n",
    "    top10 = 0\n",
    "    top100 = 0\n",
    "    top_all = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    hits = []\n",
    "    relevant_assertions = []\n",
    "\n",
    "    # Convert PyTorch dataset to a numpy array for vectorization\n",
    "    assertions_array = [assertion[0].numpy() for assertion in test_role_assertions]\n",
    "    assertions_array = np.stack(assertions_array)\n",
    "\n",
    "    '''\n",
    "    The array below is used to disregard duplicate queries.\n",
    "    For ex., if we have two assertions r(a,b) and r(a,c), the function\n",
    "    will treat r(a, ?) as a query with b and c as positive answers. It\n",
    "    will then disregard any other.\n",
    "    '''\n",
    "\n",
    "    filter_array = np.ones((assertions_array.shape), dtype=int)\n",
    "    filter_counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for assertion_idx, assertion in enumerate(assertions_array):\n",
    "\n",
    "            filter_counter = assertion_idx\n",
    "\n",
    "            if np.all(filter_array[filter_counter] == 1):\n",
    "\n",
    "                head_entity_idx = assertion[0]\n",
    "                role_entity_idx = assertion[1]\n",
    "                filter_arr = (assertions_array[:, 0] == head_entity_idx) & (assertions_array[:, 1] == role_entity_idx)\n",
    "                relevant_assertions_idcs = np.where(filter_arr)[0]\n",
    "                relevant_assertions = torch.tensor(np.array([assertions_array[idx] for idx in relevant_assertions_idcs]))\n",
    "                filter_array[relevant_assertions_idcs] = 0\n",
    "\n",
    "                assertion_scores = []\n",
    "\n",
    "                for _, tail_entity_idx in entity_to_idx_vocab.items():\n",
    "                    eval_sample = torch.tensor([head_entity_idx, role_entity_idx, tail_entity_idx]).unsqueeze(0)\n",
    "                    outputs1, outputs2, outputs3 = model(eval_sample)\n",
    "\n",
    "                    if centroid_score == False:\n",
    "                        assertion_score = torch.dist(outputs1, outputs2, p=2)\n",
    "\n",
    "                    elif alt_training == True:\n",
    "            \n",
    "                        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "                        assertion_score = cos(outputs1, outputs2) + cos(outputs2, torch.tensor(GeometricInterpretation.role_geointerps_dict[idx_to_role_vocab[role_entity_idx]].centroid))\n",
    "\n",
    "                    elif centroid_score == True and alt_training == False:\n",
    "                        assertion_score = torch.dist(outputs1, outputs2, p=2) + torch.dist(outputs2, torch.tensor(GeometricInterpretation.role_geointerps_dict[idx_to_role_vocab[role_entity_idx]].centroid)) # Change this random call to the GeoInterp class without it being passed\n",
    "\n",
    "                    assertion_scores.append((torch.tensor([head_entity_idx, role_entity_idx, tail_entity_idx]), assertion_score.item()))\n",
    "\n",
    "                sorted_scores = sorted(assertion_scores, key=lambda x: x[1])\n",
    "\n",
    "                k_list = [1, 3, 10, 100, len(assertion_scores)]\n",
    "                hit_k_values = []\n",
    "\n",
    "                for k in k_list:\n",
    "                    hit_k = any(torch.equal(scored_sample[0], assertion) for assertion in relevant_assertions for scored_sample in sorted_scores[:k])\n",
    "                    hit_k_values.append(hit_k)\n",
    "            \n",
    "                hits.append(hit_k_values)\n",
    "\n",
    "                top1 += int(hit_k_values[0])\n",
    "                top3 += int(hit_k_values[1])\n",
    "                top10 += int(hit_k_values[2])\n",
    "                top100 += int(hit_k_values[3])\n",
    "                top_all += int(hit_k_values[4])\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    hits_at_k = [round(sum(hit_values) / len(hit_values), 3) for hit_values in zip(*hits)]  # Calculate hits_at_k for each k\n",
    "    # print(f'Hits at 1, 3, 10, 100 and all: {hits_at_k}')\n",
    "\n",
    "    return hits_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, test_loss, num_epoch):\n",
    "    \n",
    "    plt.plot(range(1, num_epoch+1), train_loss, 'b-', label='Train Loss')\n",
    "    plt.plot(range(1, num_epoch+1), test_loss, 'r-', label='Test Loss')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train and Test Loss per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_hak(hits_at_k_concept, hits_at_k_roles, topk, num_epoch, eval_freq):\n",
    "\n",
    "    concept_hits_at_topk = [score_list[topk] for score_list in hits_at_k_concept]\n",
    "    roles_hits_at_topk = [scores[topk] for scores in hits_at_k_roles]\n",
    "\n",
    "    hak_dict = {0: 1,\n",
    "                1: 3,\n",
    "                2: 10,\n",
    "                3: 100,\n",
    "                4: 'all'}\n",
    "    \n",
    "    plt.plot(range(1, num_epoch+1, eval_freq), concept_hits_at_topk, 'b-', label=f'H@{hak_dict[topk]} concepts')\n",
    "\n",
    "    try:\n",
    "        plt.plot(range(1, num_epoch+1, eval_freq), roles_hits_at_topk, 'r-', label=f'H@{hak_dict[topk]} roles')\n",
    "    except:\n",
    "        print('No roles to plot.')\n",
    "\n",
    "    plt.ylim(0, 1.02)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f'hits@{hak_dict[topk]}')\n",
    "    plt.title(f'Hits@{hak_dict[topk]} every {eval_freq} epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(centroid_score, lr,\n",
    "               phi, emb_dim, epochs,\n",
    "               log_epoch, eval_freq,\n",
    "               eval_test, alt_train,\n",
    "               entity_centroid_init, concept_centroid_init,\n",
    "               role_centroid_init, loss_fn, model, optimizer,\n",
    "               train_loss_list, test_loss_list,\n",
    "               train_hits_at_k_concept, test_hits_at_k_concept,\n",
    "               train_hits_at_k_role, test_hits_at_k_role):\n",
    "    \n",
    "    model_hparams = {'centroid_score': centroid_score,\n",
    "                     'lr': lr,\n",
    "                     'phi': phi,\n",
    "                     'emb_dim': emb_dim,\n",
    "                     'epochs': epochs,\n",
    "                     'log_epoch': log_epoch,\n",
    "                     'eval_freq': eval_freq,\n",
    "                     'eval_test': eval_test,\n",
    "                     'alt_train': alt_train,\n",
    "                     'entity_centroid_init': entity_centroid_init,\n",
    "                     'concept_centroid_init': concept_centroid_init,\n",
    "                     'role_centroid_init': role_centroid_init,\n",
    "                     'loss_fn': loss_fn,\n",
    "                     'model': model,\n",
    "                     'optimizer': optimizer,\n",
    "                     'train_loss_list': train_loss_list,\n",
    "                     'test_loss_list': test_loss_list,\n",
    "                     'train_hits_at_k_concept': train_hits_at_k_concept,\n",
    "                     'test_hits_at_k_concept': test_hits_at_k_concept,\n",
    "                     'train_hits_at_k_role': train_hits_at_k_role,\n",
    "                     'test_hits_at_k_role': test_hits_at_k_role,\n",
    "                     'misc notes': []\n",
    "                     }\n",
    "    \n",
    "    return model_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, individual_vocab_idcs, concept_vocab_idcs, role_vocab_idcs, scaling_factor, dim1, dim2):\n",
    "\n",
    "    individual_embeddings = model.individual_embedding_dict.weight\n",
    "    concept_parameter_embeddings = model.concept_embedding_dict.weight\n",
    "    role_parameter_embeddings = model.role_embedding_dict.weight\n",
    "\n",
    "    individuals_for_plotting = []\n",
    "    concept_parameters_for_plotting = []\n",
    "    concept_centroid_for_plotting = []\n",
    "    role_parameters_for_plotting = []\n",
    "    role_centroid_for_plotting = []\n",
    "\n",
    "    for idx, individual in enumerate(individual_embeddings[:]):\n",
    "        individual = individual[:].detach().numpy()\n",
    "        individual_label = individual_vocab_idcs[idx]\n",
    "        final_representation = (individual, individual_label)\n",
    "        individuals_for_plotting.append(final_representation)\n",
    "\n",
    "    for idx, concept in enumerate(concept_parameter_embeddings):\n",
    "        concept_param = concept[:].detach().numpy()\n",
    "        concept_label = concept_vocab_idcs[idx]\n",
    "        final_representation = (concept_param, concept_label)\n",
    "        concept_parameters_for_plotting.append(final_representation)\n",
    "\n",
    "    for idx, key in enumerate(GeometricInterpretation.concept_geointerps_dict.keys()):\n",
    "        concept_centroid = GeometricInterpretation.concept_geointerps_dict[key].centroid[:]\n",
    "        concept_label = key + '_centroid'\n",
    "        final_representation = (concept_centroid, concept_label)\n",
    "        concept_centroid_for_plotting.append(final_representation)\n",
    "\n",
    "    for idx, role in enumerate(role_parameter_embeddings):\n",
    "        role_param = role[:].detach().numpy()\n",
    "        role_label = role_vocab_idcs[idx]\n",
    "        final_representation = (role_param, role_label)\n",
    "        role_parameters_for_plotting.append(final_representation)\n",
    "\n",
    "    for idx, key in enumerate(GeometricInterpretation.role_geointerps_dict.keys()):\n",
    "        role_centroid = GeometricInterpretation.role_geointerps_dict[key].centroid[:]\n",
    "        role_label = key + '_centroid'\n",
    "        final_representation = (role_centroid, role_label)\n",
    "        role_centroid_for_plotting.append(final_representation)\n",
    "\n",
    "\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlim(-1, scaling_factor + scaling_factor/10)\n",
    "    ax.set_ylim(-1, scaling_factor + scaling_factor/10)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.plot(0, 0, 'yo')\n",
    "\n",
    "    # Plot individual points in blue\n",
    "    for individual, label in individuals_for_plotting:\n",
    "        ax.plot(individual[dim1], individual[dim2], 'bo', label=label)\n",
    "        ax.annotate(label, xy=(individual[dim1], individual[dim2]), xytext=(3, -3), textcoords='offset points')\n",
    "\n",
    "    # Plot concept points in red\n",
    "    for concept_param, label in concept_parameters_for_plotting:\n",
    "        ax.plot(concept_param[dim1], concept_param[dim2], 'r+', label=label)\n",
    "        ax.annotate(label, xy=(concept_param[dim1], concept_param[dim2]), xytext=(3, -3), textcoords='offset points')\n",
    "\n",
    "    for concept_centroid, label in concept_centroid_for_plotting:\n",
    "        ax.plot(concept_centroid[dim1], concept_centroid[dim2], 'go', label=label)\n",
    "        ax.annotate(label, xy=(concept_centroid[dim1], concept_centroid[dim2]), xytext=(3, -3), textcoords='offset points')\n",
    "\n",
    "    # Plot role points in yellow\n",
    "    \n",
    "    for role_param, label in role_parameters_for_plotting:\n",
    "        ax.plot(role_param[dim1], role_param[dim2], 'y+', label=label)\n",
    "        ax.annotate(label, xy=(role_param[dim1], role_param[dim2]), xytext=(3, -3), textcoords='offset points')\n",
    "        \n",
    "    for role_centroid, label in role_centroid_for_plotting:\n",
    "        ax.plot(role_centroid[dim1], role_centroid[dim2], 'yo', label=label)\n",
    "        ax.annotate(label, xy=(role_centroid[dim1], role_centroid[dim2]), xytext=(3, -3), textcoords='offset points')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_concept_loader, train_role_loader,\n",
    "                test_concept_loader, test_role_loader,\n",
    "                train_concept_dset, test_concept_dset,\n",
    "                train_role_dset, test_role_dset,\n",
    "                num_epochs, loss_log_freq,\n",
    "                eval_freq, eval_train,\n",
    "                loss_function, optimizer,\n",
    "                idx_to_entity: dict, entity_to_idx: dict,\n",
    "                idx_to_concept: dict, concept_to_idx: dict,\n",
    "                idx_to_role: dict, role_to_idx: dict,\n",
    "                centroid_score = False, alt_training = False,\n",
    "                plot_loss_flag = False\n",
    "                ):\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    train_hits_at_k_concept = []\n",
    "    test_hits_at_k_concept = []\n",
    "\n",
    "    train_hits_at_k_role = []\n",
    "    test_hits_at_k_role = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train(model, train_concept_loader, train_role_loader, loss_function, optimizer, alt_training)\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss = test(model, test_concept_loader, test_role_loader, loss_function, alt_training)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        if epoch % loss_log_freq == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs} -> Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\\n')\n",
    "\n",
    "        if epoch % eval_freq == 0:\n",
    "            print(f'Epoch {epoch}: Initiating evaluation. \\n')\n",
    "            \n",
    "            try:\n",
    "                test_hak_concept = get_hits_at_k_concept_assertions(model, test_concept_dset, test_role_dset, entity_to_idx, idx_to_entity, idx_to_concept, idx_to_role, centroid_score, alt_training)\n",
    "                test_hits_at_k_concept.append(test_hak_concept)\n",
    "            except:\n",
    "                print('Exception found. H@K for the Concept Test Dataset have not been computed.')\n",
    "                pass\n",
    "\n",
    "            if eval_train == True:\n",
    "                try:\n",
    "                    train_hak_concept = get_hits_at_k_concept_assertions(model, train_concept_dset, train_role_dset, entity_to_idx, idx_to_entity, idx_to_concept, idx_to_role, centroid_score, alt_training)\n",
    "                    train_hits_at_k_concept.append(train_hak_concept)\n",
    "                except:\n",
    "                    print('Exception found. H@K for the Concept Train Dataset have not been computed.')\n",
    "                    pass\n",
    "            \n",
    "            try:\n",
    "                test_hak_role = get_hits_at_k_role_assertions(model, test_concept_dset, test_role_dset, entity_to_idx, idx_to_entity, idx_to_concept, idx_to_role, centroid_score, alt_training)\n",
    "                test_hits_at_k_role.append(test_hak_role)\n",
    "            except:\n",
    "                print('Exception found. H@K for the Role Test Dataset have not been computed.')\n",
    "                pass\n",
    "            \n",
    "            if eval_train == True:\n",
    "                try:\n",
    "                    train_hak_role = get_hits_at_k_role_assertions(model, train_concept_dset, train_role_dset, entity_to_idx, idx_to_entity, idx_to_concept, idx_to_role, centroid_score, alt_training)\n",
    "                    train_hits_at_k_role.append(train_hak_role)\n",
    "                except:\n",
    "                    print('Exception found. H@K for the Role Train Dataset have not been computed.')\n",
    "                    pass\n",
    "    \n",
    "    if plot_loss_flag == True:\n",
    "        plot_loss(train_loss_list, test_loss_list, num_epochs)\n",
    "\n",
    "    return train_loss_list, test_loss_list, train_hits_at_k_concept, test_hits_at_k_concept, train_hits_at_k_role, test_hits_at_k_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(269)\n",
    "\n",
    "CENTROID_SCORE = True # When set to True, model scores assertion w.r.t distance to the centroid and to the moving parameter for concepts/roles\n",
    "LR = 0.01\n",
    "PHI = 0 # Weighs how far the concept parameter is allowed to move\n",
    "RADIUS = SCALE_FACTOR/2 + 0.1\n",
    "EMB_DIM = 459\n",
    "LOG_EPOCH = 100000\n",
    "EVAL_TEST = False\n",
    "ALT_TRAIN = False\n",
    "NEG_SAMPLING = True\n",
    "PLOT_LOSS = False\n",
    "ENTITY_CENTROID_INIT = True\n",
    "CONCEPT_CENTROID_INIT = True\n",
    "ROLE_CENTROID_INIT = True\n",
    "\n",
    "DIM1 = 0\n",
    "DIM2 = 1\n",
    "\n",
    "if ALT_TRAIN == True:\n",
    "    loss_fn = nn.CosineEmbeddingLoss()\n",
    "else: \n",
    "    loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(269)\n",
    "\n",
    "model = FaithEL(EMB_DIM, PHI, RADIUS,\n",
    "                entity_to_idx_vocab, concept_to_idx_vocab, role_to_idx_vocab,\n",
    "                init_individual_param_to_centroid = ENTITY_CENTROID_INIT,\n",
    "                init_concept_param_to_centroid = CONCEPT_CENTROID_INIT,\n",
    "                init_role_param_to_centroid = ROLE_CENTROID_INIT)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model, idx_to_entity_vocab, idx_to_concept_vocab, idx_to_role_vocab, SCALE_FACTOR, DIM1, DIM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "EVAL_FREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Initiating evaluation. \n",
      "\n",
      "Epoch 200: Initiating evaluation. \n",
      "\n",
      "Epoch 300: Initiating evaluation. \n",
      "\n",
      "Epoch 400: Initiating evaluation. \n",
      "\n",
      "Epoch 500: Initiating evaluation. \n",
      "\n",
      "Epoch 600: Initiating evaluation. \n",
      "\n",
      "Epoch 700: Initiating evaluation. \n",
      "\n",
      "Epoch 800: Initiating evaluation. \n",
      "\n",
      "Epoch 900: Initiating evaluation. \n",
      "\n",
      "Epoch 1000: Initiating evaluation. \n",
      "\n",
      "Epoch 1100: Initiating evaluation. \n",
      "\n",
      "Epoch 1200: Initiating evaluation. \n",
      "\n",
      "Epoch 1300: Initiating evaluation. \n",
      "\n",
      "Epoch 1400: Initiating evaluation. \n",
      "\n",
      "Epoch 1500: Initiating evaluation. \n",
      "\n",
      "Epoch 1600: Initiating evaluation. \n",
      "\n",
      "Epoch 1700: Initiating evaluation. \n",
      "\n",
      "Epoch 1800: Initiating evaluation. \n",
      "\n",
      "Epoch 1900: Initiating evaluation. \n",
      "\n",
      "Epoch 2000: Initiating evaluation. \n",
      "\n",
      "Epoch 2100: Initiating evaluation. \n",
      "\n",
      "Epoch 2200: Initiating evaluation. \n",
      "\n",
      "Epoch 2300: Initiating evaluation. \n",
      "\n",
      "Epoch 2400: Initiating evaluation. \n",
      "\n",
      "Epoch 2500: Initiating evaluation. \n",
      "\n",
      "Epoch 2600: Initiating evaluation. \n",
      "\n",
      "Epoch 2700: Initiating evaluation. \n",
      "\n",
      "Epoch 2800: Initiating evaluation. \n",
      "\n",
      "Epoch 2900: Initiating evaluation. \n",
      "\n",
      "Epoch 3000: Initiating evaluation. \n",
      "\n",
      "Epoch 3100: Initiating evaluation. \n",
      "\n",
      "Epoch 3200: Initiating evaluation. \n",
      "\n",
      "Epoch 3300: Initiating evaluation. \n",
      "\n",
      "Epoch 3400: Initiating evaluation. \n",
      "\n",
      "Epoch 3500: Initiating evaluation. \n",
      "\n",
      "Epoch 3600: Initiating evaluation. \n",
      "\n",
      "Epoch 3700: Initiating evaluation. \n",
      "\n",
      "Epoch 3800: Initiating evaluation. \n",
      "\n",
      "Epoch 3900: Initiating evaluation. \n",
      "\n",
      "Epoch 4000: Initiating evaluation. \n",
      "\n",
      "Epoch 4100: Initiating evaluation. \n",
      "\n",
      "Epoch 4200: Initiating evaluation. \n",
      "\n",
      "Epoch 4300: Initiating evaluation. \n",
      "\n",
      "Epoch 4400: Initiating evaluation. \n",
      "\n",
      "Epoch 4500: Initiating evaluation. \n",
      "\n",
      "Epoch 4600: Initiating evaluation. \n",
      "\n",
      "Epoch 4700: Initiating evaluation. \n",
      "\n",
      "Epoch 4800: Initiating evaluation. \n",
      "\n",
      "Epoch 4900: Initiating evaluation. \n",
      "\n",
      "Epoch 5000: Initiating evaluation. \n",
      "\n",
      "Epoch 5100: Initiating evaluation. \n",
      "\n",
      "Epoch 5200: Initiating evaluation. \n",
      "\n",
      "Epoch 5300: Initiating evaluation. \n",
      "\n",
      "Epoch 5400: Initiating evaluation. \n",
      "\n",
      "Epoch 5500: Initiating evaluation. \n",
      "\n",
      "Epoch 5600: Initiating evaluation. \n",
      "\n",
      "Epoch 5700: Initiating evaluation. \n",
      "\n",
      "Epoch 5800: Initiating evaluation. \n",
      "\n",
      "Epoch 5900: Initiating evaluation. \n",
      "\n",
      "Epoch 6000: Initiating evaluation. \n",
      "\n",
      "Epoch 6100: Initiating evaluation. \n",
      "\n",
      "Epoch 6200: Initiating evaluation. \n",
      "\n",
      "Epoch 6300: Initiating evaluation. \n",
      "\n",
      "Epoch 6400: Initiating evaluation. \n",
      "\n",
      "Epoch 6500: Initiating evaluation. \n",
      "\n",
      "Epoch 6600: Initiating evaluation. \n",
      "\n",
      "Epoch 6700: Initiating evaluation. \n",
      "\n",
      "Epoch 6800: Initiating evaluation. \n",
      "\n",
      "Epoch 6900: Initiating evaluation. \n",
      "\n",
      "Epoch 7000: Initiating evaluation. \n",
      "\n",
      "Epoch 7100: Initiating evaluation. \n",
      "\n",
      "Epoch 7200: Initiating evaluation. \n",
      "\n",
      "Epoch 7300: Initiating evaluation. \n",
      "\n",
      "Epoch 7400: Initiating evaluation. \n",
      "\n",
      "Epoch 7500: Initiating evaluation. \n",
      "\n",
      "Epoch 7600: Initiating evaluation. \n",
      "\n",
      "Epoch 7700: Initiating evaluation. \n",
      "\n",
      "Epoch 7800: Initiating evaluation. \n",
      "\n",
      "Epoch 7900: Initiating evaluation. \n",
      "\n",
      "Epoch 8000: Initiating evaluation. \n",
      "\n",
      "Epoch 8100: Initiating evaluation. \n",
      "\n",
      "Epoch 8200: Initiating evaluation. \n",
      "\n",
      "Epoch 8300: Initiating evaluation. \n",
      "\n",
      "Epoch 8400: Initiating evaluation. \n",
      "\n",
      "Epoch 8500: Initiating evaluation. \n",
      "\n",
      "Epoch 8600: Initiating evaluation. \n",
      "\n",
      "Epoch 8700: Initiating evaluation. \n",
      "\n",
      "Epoch 8800: Initiating evaluation. \n",
      "\n",
      "Epoch 8900: Initiating evaluation. \n",
      "\n",
      "Epoch 9000: Initiating evaluation. \n",
      "\n",
      "Epoch 9100: Initiating evaluation. \n",
      "\n",
      "Epoch 9200: Initiating evaluation. \n",
      "\n",
      "Epoch 9300: Initiating evaluation. \n",
      "\n",
      "Epoch 9400: Initiating evaluation. \n",
      "\n",
      "Epoch 9500: Initiating evaluation. \n",
      "\n",
      "Epoch 9600: Initiating evaluation. \n",
      "\n",
      "Epoch 9700: Initiating evaluation. \n",
      "\n",
      "Epoch 9800: Initiating evaluation. \n",
      "\n",
      "Epoch 9900: Initiating evaluation. \n",
      "\n",
      "Epoch 10000: Initiating evaluation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, test_loss_list, train_hits_at_k_concept, test_hits_at_k_concept, train_hits_at_k_role, test_hits_at_k_role, = train_model(model,\n",
    "                                                                                                                                           train_ConceptDataLoader, train_RoleDataLoader, test_ConceptDataLoader, test_RoleDataLoader,\n",
    "                                                                                                                                           trainConceptDataset, testConceptDataset, trainRoleDataset, testRoleDataset,\n",
    "                                                                                                                                           EPOCHS, LOG_EPOCH, EVAL_FREQ, EVAL_TEST, loss_fn, optimizer,\n",
    "                                                                                                                                           idx_to_entity_vocab, entity_to_idx_vocab,\n",
    "                                                                                                                                           idx_to_concept_vocab, concept_to_idx_vocab,\n",
    "                                                                                                                                           idx_to_role_vocab, role_to_idx_vocab,\n",
    "                                                                                                                                           CENTROID_SCORE, ALT_TRAIN, PLOT_LOSS\n",
    "                                                                                                                                           )\n",
    "\n",
    "model_list.append(save_model(CENTROID_SCORE, LR, PHI, EMB_DIM, EPOCHS, LOG_EPOCH, EVAL_FREQ, EVAL_TEST, ALT_TRAIN, ENTITY_CENTROID_INIT, CONCEPT_CENTROID_INIT, ROLE_CENTROID_INIT,\n",
    "                             loss_fn, model, optimizer, train_loss_list, test_loss_list, train_hits_at_k_concept, test_hits_at_k_concept, train_hits_at_k_role, test_hits_at_k_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model, idx_to_entity_vocab, idx_to_concept_vocab, idx_to_role_vocab, SCALE_FACTOR, DIM1, DIM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = -1\n",
    "TOPK = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_score_hak(model_list[pos_list][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_hits_at_k_concept\u001b[39m\u001b[38;5;124m'\u001b[39m], model_list[pos_list][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_hits_at_k_role\u001b[39m\u001b[38;5;124m'\u001b[39m], TOPK, model_list[pos_list][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m], model_list[pos_list][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_freq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_score_hak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_hits_at_k_concept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_hits_at_k_role\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOPK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_freq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mplot_score_hak\u001b[0;34m(hits_at_k_concept, hits_at_k_roles, topk, num_epoch, eval_freq)\u001b[0m\n\u001b[1;32m      4\u001b[0m roles_hits_at_topk \u001b[38;5;241m=\u001b[39m [scores[topk] \u001b[38;5;28;01mfor\u001b[39;00m scores \u001b[38;5;129;01min\u001b[39;00m hits_at_k_roles]\n\u001b[1;32m      6\u001b[0m hak_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept_hits_at_topk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH@\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhak_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m concepts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, eval_freq), roles_hits_at_topk, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhak_dict[topk]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m roles\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kgenv/lib/python3.11/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_score_hak(model_list[pos_list]['test_hits_at_k_concept'], model_list[pos_list]['test_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])\n",
    "plot_score_hak(model_list[pos_list]['train_hits_at_k_concept'], model_list[pos_list]['train_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_hak(model_list[pos_list]['test_hits_at_k_concept'], model_list[pos_list]['test_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])\n",
    "plot_score_hak(model_list[pos_list]['train_hits_at_k_concept'], model_list[pos_list]['train_hits_at_k_role'], TOPK, model_list[pos_list]['epochs'], model_list[pos_list]['eval_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corruption for training with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_concept_assertions(train_data_concept_assertions,\n",
    "                               num_corrupt = int,\n",
    "                               entity_to_idx_vocab = dict):\n",
    "\n",
    "    candidate_entities = list(entity_to_idx_vocab.keys())\n",
    "    \n",
    "    original_assertions = torch.tensor([sample[0] for sample, label in list(train_data_concept_assertions)]) # Gets rid of the individual\n",
    "\n",
    "    num_samples = len(original_assertions)\n",
    "\n",
    "    sampled_entities = torch.tensor([torch.tensor(entity_to_idx_vocab[random.choice(candidate_entities)], dtype=torch.long) for _ in range(num_samples)])\n",
    "\n",
    "    corrupted_assertions = torch.zeros((num_samples, 2), dtype=torch.long)\n",
    "    corrupted_assertions[:, 0] = original_assertions\n",
    "    corrupted_assertions[:, 1] = sampled_entities\n",
    "\n",
    "    return corrupted_assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_role_assertions(train_data_role_assertions,\n",
    "                            num_corrupt = int,\n",
    "                            entity_to_idx_vocab=dict):\n",
    "\n",
    "    candidate_entities = list(entity_to_idx_vocab.keys())\n",
    "\n",
    "    original_head_entities = torch.tensor([sample[0] for sample, label in list(train_data_role_assertions)])\n",
    "    original_roles = torch.tensor([sample[1] for sample, label in list(train_data_role_assertions)])\n",
    "    original_tail_entities = torch.tensor([sample[2] for sample, label in list(train_data_role_assertions)])\n",
    "\n",
    "    num_samples = len(original_head_entities)\n",
    "\n",
    "    sampled_entities = torch.tensor([torch.tensor(entity_to_idx_vocab[random.choice(candidate_entities)], dtype=torch.long) for _ in range(num_samples)])\n",
    "\n",
    "    corrupted_assertions = torch.zeros((num_samples, 3), dtype=torch.long)\n",
    "    corrupted_assertions[:, 0] = original_head_entities # The original head entities\n",
    "    corrupted_assertions[:, 1] = original_roles # The original roles\n",
    "    corrupted_assertions[:, 2] = sampled_entities\n",
    "\n",
    "    return corrupted_assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
